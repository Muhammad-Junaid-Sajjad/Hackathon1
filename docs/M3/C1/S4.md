---
id: m3-c1-s4
title: GPU-Accelerated Simulation
sidebar_position: 4
keywords: ['gpu', 'acceleration', 'cuda', 'parallel', 'performance']
---

## Prerequisites

Before diving into GPU-accelerated simulation, ensure you have:

- **Completed M3-C1-S1 through S3**: Familiarity with Isaac Sim fundamentals, USD scene composition, and basic physics simulation
- **NVIDIA GPU with CUDA support**: A CUDA-capable GPU (RTX 2000 series or newer recommended) with appropriate drivers installed
- **Python and PyTorch basics**: Understanding of tensor operations, device management, and basic PyTorch memory concepts
- **Understanding of parallel computing concepts**: Basic knowledge of how parallel processing differs from sequential execution
- **Isaac Sim environment configured**: A working Isaac Sim installation with GPU dynamics capability enabled

## Learning Objectives

By the end of this section, you will be able to:

- **[Beginner]** Define GPU dynamics and explain why parallel physics simulation offers significant speedups over CPU-only approaches
- **[Beginner]** Identify the key configuration parameters required to enable GPU acceleration in Isaac Sim
- **[Intermediate]** Implement GPU-accelerated simulation contexts with proper memory configuration and contact handling
- **[Intermediate]** Configure multi-GPU setups to distribute environments across multiple CUDA devices
- **[Intermediate]** Create vectorized environments that run multiple simulation instances in parallel
- **[Advanced]** Optimize GPU memory management to prevent out-of-memory errors during large-scale training
- **[Advanced]** Architect batched simulation pipelines that balance throughput with memory constraints

## Key Concepts

| Term | Definition |
|------|------------|
| **GPU Dynamics** | PhysX feature that offloads physics computations (collision detection, constraint solving, dynamics) to GPU cores for parallel execution |
| **CUDA** | NVIDIA's parallel computing platform that enables direct GPU programming for general-purpose computations |
| **Vectorized Environment** | A simulation pattern where multiple independent environment instances run in parallel within a single simulation context |
| **GPU Heap** | Dedicated GPU memory allocation for physics simulation data structures, configured in megabytes |
| **Contact Pairs** | Maximum number of simultaneous collision interactions the GPU can track; exceeding this limit causes simulation errors |
| **ArticulationView** | Isaac Sim's batched interface for controlling multiple articulated robots simultaneously with tensor operations |
| **TensorFloat-32 (TF32)** | NVIDIA's precision format that accelerates matrix operations while maintaining acceptable numerical accuracy |
| **Memory Fraction** | The proportion of total GPU memory allocated to a process, used to prevent out-of-memory conditions |

# GPU-Accelerated Simulation

GPU-accelerated simulation represents a paradigm shift in robotics research, enabling thousands of physics simulations to run in parallel. Isaac Sim leverages NVIDIA's CUDA architecture to accelerate physics computations, dramatically increasing the throughput of reinforcement learning training and large-scale data collection. This section explores GPU-accelerated simulation techniques, from basic configuration to advanced parallel environment management.

The fundamental insight behind GPU acceleration is that physics simulation involves many independent calculations that can be parallelized. A typical humanoid robot simulation involves computing forward dynamics for multiple joints, checking collisions between many body parts, and solving constraint equations. These operations can be distributed across thousands of GPU cores, achieving speedups of 10-100x compared to CPU-only simulation.

## GPU Physics Configuration

### Enabling GPU Dynamics

Isaac Sim's PhysX backend supports GPU-accelerated physics through the GPU dynamics feature. Enabling this feature is straightforward but requires proper configuration to achieve optimal performance.

```python
# GPU-accelerated physics configuration
from omni.isaac.core import SimulationContext
from omni.isaac.core.settings import SimulationSettings
import omni.physx as _physx

class GPUAcceleratedSimulation:
    """
    Simulation configuration with GPU acceleration.
    """

    def __init__(self, config=None):
        self.config = config or self._default_config()

        # Initialize simulation context
        self.sim = SimulationContext(
            physics_dt=self.config['physics_dt'],
            rendering_dt=self.config['rendering_dt'],
            stage_units_in_meters=self.config['stage_units'],
            backend="torch" if self.config.get('use_torch', False) else "numpy"
        )

        # Configure GPU physics
        self._configure_gpu_physics()

    def _default_config(self):
        """Default configuration for GPU simulation."""
        return {
            'physics_dt': 0.001,        # 1ms physics timestep
            'rendering_dt': 0.0167,     # ~60 FPS rendering
            'stage_units': 0.01,         # USD units = centimeters
            'gpu_dynamics': True,         # Enable GPU physics
            'gpu_heap_size': 8 * 1024,   # 8GB GPU heap
            'max_gpu_contact_pairs': 65536,
            'ccd_enabled': False,         # Continuous collision detection
            'num_solver_iterations': 64,
        }

    def _configure_gpu_physics(self):
        """Configure GPU-accelerated physics."""
        # Get PhysX interface
        physx_interface = _physx.get_physx_interface()

        # Enable GPU dynamics
        if self.config.get('gpu_dynamics', True):
            physx_interface.enable_gpu_dynamics(True)

            # Configure GPU memory
            self._configure_gpu_memory()

            # Configure contact handling
            self._configure_gpu_contacts()

    def _configure_gpu_memory(self):
        """Configure GPU memory allocation."""
        # Set GPU heap size
        heap_size = self.config.get('gpu_heap_size', 8 * 1024)  # MB
        # This is typically done through settings
        import omni.kit.settings
        settings = omni.kit.settings.get_settings()
        settings.set_int("/physics/gpuHeapSize", heap_size)

    def _configure_gpu_contacts(self):
        """Configure GPU contact handling."""
        max_contacts = self.config.get('max_gpu_contact_pairs', 65536)
        import omni.kit.settings
        settings = omni.kit.settings.get_settings()
        settings.set_int("/physics/maxGpuContactPairs", max_contacts)

    def verify_gpu_acceleration(self):
        """Verify that GPU acceleration is active."""
        physx_interface = _physx.get_physx_interface()

        # Check if GPU dynamics are enabled
        is_gpu_enabled = physx_interface.is_gpu_dynamics_enabled()

        # Get device info
        import torch
        device_info = {
            'cuda_available': torch.cuda.is_available(),
            'device_count': torch.cuda.device_count() if torch.cuda.is_available() else 0,
            'device_name': torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'N/A',
            'memory_total': torch.cuda.get_device_properties(0).total_memory / (1024**3) if torch.cuda.is_available() else 0,
        }

        return {
            'gpu_dynamics_enabled': is_gpu_enabled,
            'device_info': device_info,
        }

    def get_performance_stats(self):
        """Get performance statistics for GPU simulation."""
        import omni.kit.app

        app = omni.kit.app.get_app()
        stats = {
            'physics_fps': app.get_physics_fps(),
            'gpu_utilization': self._get_gpu_utilization(),
            'memory_usage': self._get_memory_usage(),
        }
        return stats

    def _get_gpu_utilization(self):
        """Get GPU utilization."""
        try:
            import pynvml
            pynvml.nvmlInit()
            handle = pynvml.nvmlDeviceGetHandleByIndex(0)
            utilization = pynvml.nvmlDeviceGetUtilizationRates(handle)
            return {
                'gpu': utilization.gpu,
                'memory': utilization.memory,
            }
        except:
            return {'gpu': 'N/A', 'memory': 'N/A'}

    def _get_memory_usage(self):
        """Get GPU memory usage."""
        try:
            import torch
            if torch.cuda.is_available():
                memory_allocated = torch.cuda.memory_allocated() / (1024**3)
                memory_reserved = torch.cuda.memory_reserved() / (1024**3)
                return {
                    'allocated_gb': memory_allocated,
                    'reserved_gb': memory_reserved,
                }
        except:
            pass
        return {'allocated_gb': 'N/A', 'reserved_gb': 'N/A'}
```

### Multi-GPU Configuration

For large-scale simulations, multiple GPUs can be leveraged to run parallel environments. Isaac Sim supports distributing simulations across multiple GPU devices.

```python
# Multi-GPU simulation configuration
import torch
import omni.isaac.core as isaac_core

class MultiGPUSimulation:
    """
    Multi-GPU simulation manager for parallel environment execution.
    """

    def __init__(self, num_environments, config=None):
        self.num_environments = num_environments
        self.config = config or {}

        # Get available GPUs
        self.available_devices = self._get_available_devices()
        self.num_gpus = len(self.available_devices)

        # Create environment-to-GPU mapping
        self.env_to_gpu = self._create_device_mapping()

        # Create simulation contexts for each GPU
        self.simulations = {}
        self._create_simulations()

    def _get_available_devices(self):
        """Get list of available CUDA devices."""
        if not torch.cuda.is_available():
            return ['cpu']

        return [f'cuda:{i}' for i in range(torch.cuda.device_count())]

    def _create_device_mapping(self):
        """Map environments to GPU devices."""
        mapping = {}
        for env_id in range(self.num_environments):
            gpu_id = env_id % self.num_gpus
            mapping[env_id] = self.available_devices[gpu_id]
        return mapping

    def _create_simulations(self):
        """Create simulation context for each GPU."""
        # Group environments by GPU
        envs_by_gpu = {}
        for env_id, gpu in self.env_to_gpu.items():
            if gpu not in envs_by_gpu:
                envs_by_gpu[gpu] = []
            envs_by_gpu[gpu].append(env_id)

        # Create simulations for each GPU
        for gpu, env_ids in envs_by_gpu.items():
            if gpu != 'cpu':
                with torch.cuda.device(gpu):
                    self.simulations[gpu] = self._create_gpu_simulation(gpu, env_ids)

    def _create_gpu_simulation(self, gpu, env_ids):
        """Create a simulation for a specific GPU."""
        sim = GPUAcceleratedSimulation(self.config)
        sim.sim.set_cuda_device(gpu)

        return {
            'simulation': sim,
            'environments': env_ids,
            'device': gpu,
        }

    def step_all(self, actions_dict):
        """
        Step all environments.

        Args:
            actions_dict: Dict of {env_id: action}

        Returns:
            Dict of {env_id: (obs, reward, done, info)}
        """
        results = {}

        # Group actions by GPU
        actions_by_gpu = {}
        for env_id, action in actions_dict.items():
            gpu = self.env_to_gpu[env_id]
            if gpu not in actions_by_gpu:
                actions_by_gpu[gpu] = {}
            actions_by_gpu[gpu][env_id] = action

        # Step simulations on each GPU
        for gpu, sim_info in self.simulations.items():
            sim = sim_info['simulation']
            env_ids = sim_info['environments']

            # Step this simulation
            gpu_results = self._step_simulation(sim, env_ids, actions_by_gpu.get(gpu, {}))
            results.update(gpu_results)

        return results

    def _step_simulation(self, sim, env_ids, actions):
        """Step a single simulation with multiple environments."""
        results = {}

        for env_id in env_ids:
            action = actions.get(env_id)
            obs, reward, done, info = sim.step(action)

            if done:
                sim.reset()
                obs = sim.get_observation()

            results[env_id] = (obs, reward, done, info)

        return results

    def reset_all(self):
        """Reset all environments."""
        for sim_info in self.simulations.values():
            sim_info['simulation'].reset()

    def get_observations(self):
        """Get observations from all environments."""
        return {
            env_id: sim_info['simulation'].get_observation()
            for env_id, sim_info in self.simulations.items()
        }
```

## Parallel Environment Management

### Environment Vectorization

Isaac Gym provides vectorized environment management that can run multiple environments in parallel within a single simulation instance. This approach achieves the highest throughput by minimizing overhead.

```python
# Vectorized environment management
from omni.isaac.gym import GymVecEnv
from omni.isaac.gym.vec_env import VecEnvBase
import numpy as np

class HumanoidVecEnv(VecEnvBase):
    """
    Vectorized environment for humanoid robot training.
    Runs multiple environment instances in parallel.
    """

    def __init__(self, config):
        """
        Initialize vectorized environment.

        Args:
            config: Configuration dict with:
                - num_envs: Number of parallel environments
                - env_spacing: Spacing between environments
                - robot_asset_path: Path to robot USD
                - stage_units: USD units in meters
        """
        self.num_envs = config['num_envs']
        self.env_spacing = config.get('env_spacing', 2.0)

        # Initialize base class
        super().__init__(self.num_envs)

        # Create simulation
        self._create_simulation()

        # Create environments
        self._create_environments(config)

        # Set up observation and action spaces
        self._setup_spaces()

    def _create_simulation(self):
        """Create the simulation context."""
        from omni.isaac.core import SimulationContext

        self.sim = SimulationContext(
            physics_dt=0.001,
            rendering_dt=0.0167,
            stage_units_in_meters=0.01,
        )

        # Configure GPU dynamics
        import omni.physx as _physx
        physx = _physx.get_physx_interface()
        physx.enable_gpu_dynamics(True)

    def _create_environments(self, config):
        """Create vectorized environments."""
        # Create articulation view for all environments
        from omni.isaac.core.articulations import ArticulationView

        self.robot_view = ArticulationView(
            prim_paths_expr=[
                f"/World/env_{i}/Robot"
                for i in range(self.num_envs)
            ]
        )
        self.robot_view.initialize()

        # Get observation and action dimensions
        self.num_dof = self.robot_view.num_dof

        # Create ground plane for each environment
        self._create_ground_planes()

    def _create_ground_planes(self):
        """Create ground planes for all environments."""
        for i in range(self.num_envs):
            env_offset = np.array([i * self.env_spacing, 0, 0])
            self._create_ground(f"/World/env_{i}/Ground", env_offset)

    def _create_ground(self, path, offset):
        """Create a ground plane."""
        from pxr import UsdGeom, UsdPhysics, Gf, Sdf
        import omni.usd

        stage = omni.usd.get_context().get_stage()

        # Create plane
        plane = UsdGeom.Plane.Define(stage, path)
        plane.AddTranslateOp().Set(Gf.Vec3f(*offset))
        plane.AddRotateXYZOp().Set(Gf.Vec3f(90, 0, 0))
        plane.GetSizeAttr().Set(10.0)

        # Add collision
        UsdPhysics.CollisionAPI.Apply(plane.GetPrim())

        # Add static rigid body
        UsdPhysics.RigidBodyAPI.Apply(plane.GetPrim())

    def _setup_spaces(self):
        """Set up observation and action spaces."""
        import gymnasium as gym
        from gymnasium.spaces import Box

        # Observation space: joint positions, velocities, root state
        obs_dim = self.num_dof * 2 + 7 + 3  # pos + vel + root pose + root vel
        self.observation_space = Box(
            low=-np.inf, high=np.inf, shape=(obs_dim,), dtype=np.float32
        )

        # Action space: joint torques/positions
        self.action_space = Box(
            low=-1.0, high=1.0, shape=(self.num_dof,), dtype=np.float32
        )

    def reset(self):
        """Reset all environments."""
        # Reset robot states
        self.robot_view.set_joint_positions(self._get_initial_positions())
        self.robot_view.set_joint_velocities(np.zeros(self.num_dof))

        return self._get_observations()

    def step(self, actions):
        """
        Step all environments.

        Args:
            actions: Array of actions, shape (num_envs, num_dof)

        Returns:
            observations: Array of observations
            rewards: Array of rewards
            dones: Array of done flags
            infos: Array of info dicts
        """
        # Apply actions
        self.robot_view.set_joint_effort_targets(actions)

        # Step physics
        for _ in range(10):  # Substeps
            self.sim.step()

        # Get observations
        obs = self._get_observations()

        # Compute rewards and dones
        rewards, dones, infos = self._compute_rewards_and_dones(obs)

        return obs, rewards, dones, infos

    def _get_observations(self):
        """Get observations from all environments."""
        joint_pos = self.robot_view.get_joint_positions()  # (num_envs, num_dof)
        joint_vel = self.robot_view.get_joint_velocities()  # (num_envs, num_dof)
        root_state = self.robot_view.get_root_pose_and_velocity()  # (num_envs, 13)

        # Concatenate
        obs = np.concatenate([joint_pos, joint_vel, root_state], axis=-1)
        return obs

    def _get_initial_positions(self):
        """Get initial joint positions for reset."""
        return np.zeros((self.num_envs, self.num_dof))

    def _compute_rewards_and_dones(self, obs):
        """Compute rewards and termination conditions."""
        rewards = np.zeros(self.num_envs)
        dones = np.zeros(self.num_envs, dtype=bool)
        infos = [{} for _ in range(self.num_envs)]

        # Simplified reward based on joint velocities (minimize movement)
        joint_vel = obs[:, self.num_dof:self.num_dof*2]
        rewards = -np.mean(np.abs(joint_vel), axis=-1)

        # Check for falls (simplified)
        root_orientation = obs[:, 7:11]
        dones = self._check_falls(root_orientation)

        return rewards, dones, infos

    def _check_falls(self, orientations):
        """Check if robots have fallen based on orientation."""
        # Simplified: check if up vector points approximately up
        import numpy as np
        from scipy.spatial.transform import Rotation

        falls = np.zeros(self.num_envs, dtype=bool)

        for i in range(self.num_envs):
            try:
                rot = Rotation.from_quat(orientations[i])
                up = rot.apply([0, 0, 1])
                if up[2] < 0.5:  # Robot is not upright
                    falls[i] = True
            except:
                falls[i] = True

        return falls

    def close(self):
        """Clean up resources."""
        if self.sim:
            self.sim.close()
```

## Performance Optimization

### Memory Management

Efficient memory management is crucial for GPU-accelerated simulation. The following patterns help optimize memory usage and prevent out-of-memory errors.

```python
# Memory optimization for GPU simulation
import torch
import gc

class MemoryOptimizedSimulation:
    """
    Simulation with memory optimization techniques.
    """

    def __init__(self, config=None):
        self.config = config or {}
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

        # Configure PyTorch memory allocation
        self._configure_torch_memory()

        # Tracking
        self.observation_cache = {}
        self.action_buffer = []

    def _configure_torch_memory(self):
        """Configure PyTorch memory allocation for optimal performance."""
        if self.device.type == 'cuda':
            # Enable TensorFloat-32 for faster matrix operations
            torch.backends.cuda.matmul.allow_tf32 = True
            torch.backends.cudnn.allow_tf32 = True

            # Configure memory growth
            torch.cuda.empty_cache()

            # Set memory fraction (optional, to leave headroom)
            max_memory = torch.cuda.get_device_properties(0).total_memory
            # torch.cuda.set_per_process_memory_fraction(0.9)

    def allocate_tensors(self, shape, dtype=torch.float32):
        """Allocate tensors with proper memory alignment."""
        return torch.empty(shape, dtype=dtype, device=self.device)

    def collect_observations(self, observations_dict):
        """
        Collect observations from multiple sources efficiently.
        Uses in-place operations where possible.
        """
        if not observations_dict:
            return None

        # Get maximum shape
        max_shape = max(obs.shape for obs in observations_dict.values())

        # Allocate output tensor
        output = torch.zeros(
            (len(observations_dict),) + max_shape,
            dtype=torch.float32,
            device=self.device
        )

        # Copy observations in-place
        for i, obs in enumerate(observations_dict.values()):
            if isinstance(obs, np.ndarray):
                obs_tensor = torch.from_numpy(obs).to(self.device)
            else:
                obs_tensor = obs.to(self.device) if hasattr(obs, 'to') else obs

            output[i] = obs_tensor

        return output

    def batched_step(self, envs, actions, batch_size=32):
        """
        Step multiple environments in batches for memory efficiency.

        Args:
            envs: List of environment instances
            actions: Dict of {env_id: action}
            batch_size: Number of envs to process simultaneously

        Yields:
            Batches of results
        """
        env_ids = list(envs.keys())

        for i in range(0, len(env_ids), batch_size):
            batch_ids = env_ids[i:i+batch_size]
            batch_actions = {eid: actions[eid] for eid in batch_ids if eid in actions}

            # Process batch
            batch_results = {}
            for env_id in batch_ids:
                env = envs[env_id]
                action = batch_actions.get(env_id)
                result = env.step(action)
                batch_results[env_id] = result

            yield batch_results

            # Clean up intermediate tensors
            gc.collect()
            if self.device.type == 'cuda':
                torch.cuda.empty_cache()

    def get_memory_stats(self):
        """Get current memory statistics."""
        stats = {
            'device': str(self.device),
        }

        if self.device.type == 'cuda':
            stats['allocated_gb'] = torch.cuda.memory_allocated() / (1024**3)
            stats['reserved_gb'] = torch.cuda.memory_reserved() / (1024**3)
            stats['max_allocated_gb'] = torch.cuda.max_memory_allocated() / (1024**3)

        return stats

    def clear_cache(self):
        """Clear observation cache and force garbage collection."""
        self.observation_cache.clear()
        gc.collect()
        if self.device.type == 'cuda':
            torch.cuda.empty_cache()
```

## Connection to Capstone

GPU-accelerated simulation is a foundational enabler for the **Voice-to-Plan-to-Navigate-to-Vision-to-Manipulate** capstone pipeline:

- **Voice (Speech Recognition)**: High-throughput simulation allows training robust speech-to-command models by generating diverse acoustic scenarios and robot responses in parallel, ensuring the voice interface handles real-world variability
- **Plan (Task Planning)**: GPU parallelization enables rapid evaluation of thousands of candidate action sequences, allowing the planner to explore larger search spaces and find optimal paths faster
- **Navigate (Motion Planning)**: Vectorized environments train navigation policies 100x faster than real-time, making it practical to learn collision-free locomotion across diverse terrains and obstacle configurations
- **Vision (Perception)**: Parallel rendering pipelines generate synthetic training data at scale, enabling domain randomization that bridges the sim-to-real gap for visual perception models
- **Manipulate (Grasping and Manipulation)**: Contact-rich manipulation requires solving many constraint equations per timestep; GPU dynamics makes learning dexterous skills computationally feasible within reasonable training budgets

The memory optimization and multi-GPU patterns covered in this section directly support the capstone's requirement to train integrated policies that span all five pipeline stages. Without GPU acceleration, the sample complexity of end-to-end humanoid control would make the capstone's learning objectives impractical to achieve.

## Next Steps

GPU-accelerated simulation enables training policies at unprecedented scales. The next section will explore PhysX 5 integration, diving deeper into the physics engine's capabilities and how to leverage advanced features for more realistic and complex humanoid simulations.
