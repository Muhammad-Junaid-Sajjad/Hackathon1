---
id: m3-c1-s3
title: Isaac Sim Simulation Loop
sidebar_position: 3
keywords: ['simulation', 'loop', 'physics', 'step', 'time']
---

# Isaac Sim Simulation Loop

## Prerequisites

Before diving into this section, ensure you have a solid understanding of the following:

- **Python fundamentals**: Classes, inheritance, callbacks, and async programming patterns
- **Basic physics simulation concepts**: Understanding of time steps, integration methods, and state variables
- **USD scene structure**: Familiarity with prims, paths, and the scene graph hierarchy from previous sections
- **Isaac Sim installation**: A working Isaac Sim environment with the Python API accessible
- **NumPy and PyTorch basics**: Array operations and tensor manipulation for observation handling

## Learning Objectives

By the end of this section, you will be able to:

| Level | Objective |
|-------|-----------|
| **Beginner** | Define the core components of the SimulationContext class and identify when each stepping method should be used |
| **Beginner** | Identify the difference between physics time, rendering time, and wall-clock time |
| **Intermediate** | Implement a custom simulation loop with callbacks for pre-step and post-step processing |
| **Intermediate** | Configure physics parameters including timestep, solver iterations, and GPU dynamics |
| **Advanced** | Architect an episode management system for reinforcement learning training workflows |
| **Advanced** | Optimize simulation throughput using observation caching, batching, and parallel instances |

## Key Concepts

| Term | Definition |
|------|------------|
| **SimulationContext** | The primary Isaac Sim class that manages physics stepping, time control, and scene synchronization |
| **Physics Timestep (dt)** | The discrete time interval between physics solver updates, typically 0.001s for robotics |
| **Rendering Timestep** | The interval between visual frame updates, independent of physics frequency |
| **ArticulationView** | A batched interface for querying and controlling robot joint states efficiently |
| **Episode** | A complete sequence of simulation steps from reset to termination, used in RL training |
| **Callback** | A registered function executed at specific points in the simulation loop (pre-step, post-step) |
| **Time Scale** | A multiplier that controls simulation speed relative to wall-clock time (1.0 = real-time) |
| **Root State** | The position, orientation, and velocities of the robot's base link in world coordinates |

:::danger Latency Trap Warning
**Physics stepping at 1kHz requires local GPU computation.** Remote simulation adds unacceptable delays:
- Run simulation loop on local GPU (RTX 5070 Ti or better)
- Never stream physics state over network during training
- Deploy trained policies to Jetson for edge execution
:::

---

The simulation loop is the heartbeat of any physics simulation, orchestrating the advancement of physical state through discrete time steps. In Isaac Sim, the simulation loop is managed through the `SimulationContext` class, which provides a high-level interface for controlling simulation execution, stepping physics, and synchronizing with external systems. Understanding the simulation loop architecture is essential for developing responsive, accurate, and efficient robotics simulations.

Isaac Sim's simulation loop is built on top of the Omniverse Kit framework, which provides the underlying application infrastructure. The loop operates by repeatedly advancing physics simulation while also updating rendering, processing user input, and executing any registered callbacks. This multi-faceted approach ensures that simulations not only produce accurate physics results but also remain interactive and visually responsive.

## SimulationContext Architecture

### Core Concepts and Initialization

The `SimulationContext` class serves as the primary interface for simulation control. It manages the simulation time, physics stepping, and provides access to scene information. When creating a simulation, you typically start by instantiating a `SimulationContext` which initializes the physics world and prepares the simulation for execution.

```python
# SimulationContext initialization and configuration
from omni.isaac.core import SimulationContext
from omni.isaac.core.settings import SimulationSettings
import omni.timeline

class HumanoidSimulation:
    """
    Main simulation class for humanoid robot control.
    Manages the simulation loop, physics stepping, and state observation.
    """

    def __init__(self, config=None):
        """
        Initialize the simulation context.

        Args:
            config: Optional configuration dictionary with simulation parameters
        """
        self.config = config or self._default_config()

        # Get or create the simulation context
        self.sim = SimulationContext(
            physics_dt=self.config['physics_dt'],
            rendering_dt=self.config['rendering_dt'],
            stage_units_in_meters=self.config['stage_units'],
            backend="torch" if self.config.get('use_torch', False) else "numpy"
        )

        # Configure simulation settings
        self._configure_physics()

        # Timeline control
        self.timeline = omni.timeline.get_timeline_interface()

        # State tracking
        self.is_running = False
        self.current_time = 0.0
        self.current_step = 0

        # Callbacks
        self.step_callbacks = []
        self.render_callbacks = []

    def _default_config(self):
        """Return default configuration."""
        return {
            'physics_dt': 0.001,      # 1ms physics timestep
            'rendering_dt': 0.0167,   # ~60 FPS rendering
            'stage_units': 0.01,      # USD units = centimeters
            'num_substeps': 10,       # Physics substeps per frame
            'gravity': [0, -9.81, 0],
            'use_torch': False,
        }

    def _configure_physics(self):
        """Configure physics engine parameters."""
        # Set gravity
        self.sim.set_gravity(self.config['gravity'])

        # Configure solver settings
        physics_scene = self.sim.get_physics_scene()
        if physics_scene:
            # Set solver iteration count
            solver_iterations = self.config.get('solver_iterations', 64)
            physics_scene.GetAttribute("solverIterationCount").Set(solver_iterations)

            # Enable/disable features
            self.sim.set_physics_engine_flag("enable_ccd", self.config.get('enable_ccd', False))
            self.sim.set_physics_engine_flag("enable_gpu_dynamics", self.config.get('gpu_dynamics', True))

    def initialize(self, stage=None):
        """
        Initialize the simulation.

        Args:
            stage: Optional USD stage to load
        """
        if stage:
            self.sim.initialize_stage(stage)
        else:
            self.sim.initialize()

        print(f"Simulation initialized")
        print(f"  Physics timestep: {self.sim.get_physics_dt()}s")
        print(f"  Rendering timestep: {self.sim.get_rendering_dt()}s")
        print(f"  Gravity: {self.sim.get_gravity()}")

    def load_stage(self, usd_path):
        """
        Load a USD stage.

        Args:
            usd_path: Path to the USD file
        """
        self.sim.load_stage(usd_path)
        print(f"Loaded stage: {usd_path}")
```

### Simulation Stepping

The simulation step is the fundamental operation that advances the physics state. The `SimulationContext` provides several methods for controlling simulation advancement, from simple single-step operations to continuous playback mode. Understanding the relationship between physics time and wall-clock time is crucial for implementing real-time or faster-than-real-time simulations.

```python
# Simulation stepping methods
class HumanoidSimulation(HumanoidSimulation):

    def step(self, num_steps=1, callback=None):
        """
        Advance the simulation by a fixed number of steps.

        Args:
            num_steps: Number of physics steps to take
            callback: Optional callback function called after each step

        Returns:
            List of observations from each step
        """
        observations = []

        for i in range(num_steps):
            # Execute pre-step callbacks
            self._execute_callbacks('pre_step', i)

            # Step the physics
            self.sim.step()

            # Execute post-step callbacks
            self._execute_callbacks('post_step', i)

            # Collect observation
            if callback:
                obs = callback(self)
                observations.append(obs)

            self.current_step += 1

        self.current_time = self.current_step * self.sim.get_physics_dt()
        return observations

    def play(self):
        """Start continuous simulation playback."""
        self.is_running = True
        self.timeline.play()
        print("Simulation playing")

    def pause(self):
        """Pause the simulation."""
        self.is_running = False
        self.timeline.pause()
        print("Simulation paused")

    def stop(self):
        """Stop and reset the simulation."""
        self.is_running = False
        self.timeline.stop()
        self.current_time = 0.0
        self.current_step = 0
        print("Simulation stopped and reset")

    def reset(self):
        """Reset the simulation to initial state."""
        self.timeline.stop()
        self.sim.reset()
        self.current_time = 0.0
        self.current_step = 0
        print("Simulation reset")

    def step_async(self, num_steps=1):
        """
        Advance simulation asynchronously.
        Useful for non-blocking workflows.
        """
        # This would typically use Isaac Sim's async API
        # For now, we use synchronous stepping
        return self.step(num_steps)

    def _execute_callbacks(self, callback_type, step_index):
        """Execute registered callbacks of a given type."""
        callbacks = self.step_callbacks if callback_type == 'step' else []

        for callback in callbacks:
            if callback['type'] == callback_type or callback['type'] == 'all':
                callback['func'](self, step_index)

    def register_step_callback(self, callback_func, callback_type='all'):
        """
        Register a callback to be executed each simulation step.

        Args:
            callback_func: Function to call (signature: func(sim, step_index))
            callback_type: 'pre_step', 'post_step', or 'all'
        """
        self.step_callbacks.append({
            'func': callback_func,
            'type': callback_type
        })

    def run_for_duration(self, duration_seconds, callbacks=None):
        """
        Run simulation for a specified duration.

        Args:
            duration_seconds: Wall-clock duration to simulate
            callbacks: Optional list of callbacks to run during simulation

        Returns:
            Total number of steps taken
        """
        target_time = self.current_time + duration_seconds
        steps_taken = 0

        while self.current_time < target_time:
            self.step()
            steps_taken += 1

            # Check for early termination
            if self.is_terminated():
                print(f"Simulation terminated at step {steps_taken}")
                break

        return steps_taken

    def run_until(self, target_time, callbacks=None):
        """
        Run simulation until reaching a target simulation time.

        Args:
            target_time: Target simulation time in seconds
            callbacks: Optional callbacks

        Returns:
            Number of steps taken
        """
        steps_taken = 0
        while self.current_time < target_time:
            self.step()
            steps_taken += 1

        return steps_taken
```

### Time Management and Synchronization

Managing time in a simulation involves coordinating multiple clocks: simulation time (the time being simulated), wall-clock time (actual elapsed time), and rendering time (the time displayed to users). Isaac Sim provides tools for controlling these different time domains and synchronizing simulation with external systems.

```python
# Time management and synchronization
class HumanoidSimulation(HumanoidSimulation):

    def get_sim_time(self):
        """Get the current simulation time."""
        return self.current_time

    def get_wall_time(self):
        """Get the current wall-clock time."""
        import time
        return time.time()

    def get_time_since_reset(self):
        """Get wall-clock time since simulation was last reset."""
        return self.get_wall_time() - self._reset_time

    def get_step_count(self):
        """Get the current step count."""
        return self.current_step

    def get_fps(self):
        """Get the current physics simulation rate."""
        return 1.0 / self.sim.get_physics_dt()

    def set_time_scale(self, scale):
        """
        Set the time scale factor.

        Args:
            scale: 1.0 = real-time, 2.0 = 2x real-time, 0.5 = half speed
        """
        self.time_scale = scale

    def get_effective_dt(self):
        """Get the effective physics timestep considering time scale."""
        return self.sim.get_physics_dt() * getattr(self, 'time_scale', 1.0)

    def synchronize_with_wall_clock(self, target_real_time=True):
        """
        Synchronize simulation to wall-clock time.

        Args:
            target_real_time: If True, run at real-time; otherwise run as fast as possible
        """
        import time

        if target_real_time:
            self.time_scale = 1.0
            self.target_frame_duration = self.sim.get_physics_dt()
        else:
            self.time_scale = 0  # Run as fast as possible

    def run_realtime_loop(self, duration_seconds=None):
        """
        Run simulation at approximately real-time speed.
        Uses wall-clock timing to pace simulation.
        """
        import time

        self.play()
        self._reset_time = self.get_wall_time()

        target_duration = duration_seconds if duration_seconds else float('inf')
        start_wall = self.get_wall_time()

        while self.is_running:
            current_wall = self.get_wall_time()
            elapsed = current_wall - start_wall

            if elapsed >= target_duration:
                break

            # Calculate how many steps we should have taken
            target_sim_time = elapsed * self.time_scale
            steps_needed = int((target_sim_time - self.current_time) / self.sim.get_physics_dt())

            if steps_needed > 0:
                self.step(steps_needed)

            # Yield to allow rendering
            time.sleep(0.001)

    def is_terminated(self):
        """Check if simulation termination conditions are met."""
        # Default implementation - override for custom termination
        return False

    def check_timeout(self):
        """Check if maximum simulation time has been exceeded."""
        max_time = self.config.get('max_time', float('inf'))
        return self.current_time >= max_time
```

## Observation and State Management

### Collecting Robot State

During simulation, you need to collect observations from the robot and environment. These observations may include joint positions, velocities, accelerations, end-effector positions, contact states, and sensor readings. Isaac Sim provides a rich API for querying the current state of simulated entities.

```python
# State observation and collection
from omni.isaac.core.utils.types import ArticulationAction
from omni.isaac.core.articulations import ArticulationView
import numpy as np
import torch

class HumanoidSimulation(HumanoidSimulation):

    def __init__(self, config=None):
        super().__init__(config)
        self.robot = None
        self.articulation_view = None

    def setup_robot(self, robot_prim_path):
        """
        Set up robot articulation view for state observation.

        Args:
            robot_prim_path: USD path to the robot articulation root
        """
        self.robot_prim_path = robot_prim_path
        self.articulation_view = ArticulationView(prim_paths_expr=[robot_prim_path])
        self.articulation_view.initialize()
        print(f"Robot articulation initialized: {robot_prim_path}")
        print(f"  Degrees of freedom: {self.articulation_view.num_dof}")

    def get_observation(self):
        """
        Get the current robot observation.

        Returns:
            Dictionary containing all observation components
        """
        if self.articulation_view is None:
            return {}

        # Get joint state
        joint_positions = self.articulation_view.get_joint_positions()
        joint_velocities = self.articulation_view.get_joint_velocities()
        joint_efforts = self.articulation_view.get_joint_efforts()

        # Get root state (position + orientation + linear velocity + angular velocity)
        root_state = self.articulation_view.get_root_pose_and_velocity()

        # Get end-effector poses (if configured)
        end_effector_poses = self._get_end_effector_poses()

        # Get contact states
        contact_states = self._get_contact_states()

        return {
            'joint_positions': joint_positions,
            'joint_velocities': joint_velocities,
            'joint_efforts': joint_efforts,
            'root_state': root_state,
            'end_effector_poses': end_effector_poses,
            'contact_states': contact_states,
            'simulation_time': self.current_time,
        }

    def get_observation_tensor(self, device='cpu'):
        """
        Get observation as a tensor (for RL training).

        Args:
            device: Device to place tensor on ('cpu' or 'cuda')

        Returns:
            Flattened observation tensor
        """
        obs = self.get_observation()

        # Concatenate all observations into a single tensor
        tensors = []

        if obs['joint_positions'] is not None:
            tensors.append(torch.tensor(obs['joint_positions'], device=device))

        if obs['joint_velocities'] is not None:
            tensors.append(torch.tensor(obs['joint_velocities'], device=device))

        if obs['root_state'] is not None:
            tensors.append(torch.tensor(obs['root_state'], device=device))

        return torch.cat(tensors)

    def _get_end_effector_poses(self):
        """Get end-effector positions and orientations."""
        end_effector_paths = [
            "/Robot/LeftHand/EndEffector",
            "/Robot/RightHand/EndEffector",
        ]

        poses = {}
        for path in end_effector_paths:
            prim = self.sim.stage.GetPrimAtPath(path)
            if prim:
                # Get world transform
                from pxr import UsdGeom, Gf
                xform = UsdGeom.Xformable(prim)
                world_transform = xform.ComputeLocalToWorldTransform(
                    Usd.TimeCode.Default()
                )
                poses[path] = {
                    'position': world_transform.ExtractTranslation(),
                    'orientation': world_transform.ExtractRotation(),
                }

        return poses

    def _get_contact_states(self):
        """Get contact states for all feet/hands."""
        contact_prims = [
            "/Robot/LeftFoot",
            "/Robot/RightFoot",
        ]

        contacts = {}
        for path in contact_prims:
            prim = self.sim.stage.GetPrimAtPath(path)
            if prim:
                # Check for contacts using physics interface
                contacts[path] = self._check_contact(prim)

        return contacts

    def _check_contact(self, prim):
        """Check if a prim is in contact with anything."""
        # Implementation depends on physics interface
        return False

    def apply_action(self, action):
        """
        Apply an action to the robot joints.

        Args:
            action: ArticulationAction or array of joint commands
        """
        if self.articulation_view is None:
            return

        if isinstance(action, ArticulationAction):
            self.articulation_view.apply_action(action)
        else:
            # Assume action is array of joint torques/positions
            self.articulation_view.set_joint_effort_targets(action)

    def set_joint_positions(self, positions, joint_indices=None):
        """
        Set joint positions directly (kinematic control).

        Args:
            positions: Target joint positions
            joint_indices: Optional list of joint indices to set
        """
        if joint_indices is None:
            joint_indices = list(range(len(positions)))

        self.articulation_view.set_joint_positions(positions, joint_indices)

    def set_joint_velocities(self, velocities, joint_indices=None):
        """Set joint velocities directly."""
        if joint_indices is None:
            joint_indices = list(range(len(velocities)))

        self.articulation_view.set_joint_velocities(velocities, joint_indices)

    def set_joint_efforts(self, efforts, joint_indices=None):
        """Set joint efforts/torques directly."""
        if joint_indices is None:
            joint_indices = list(range(len(efforts)))

        self.articulation_view.set_joint_effort_targets(efforts, joint_indices)
```

### Episode Management

Reinforcement learning and episodic simulations require tracking episode boundaries, resetting environments, and managing episode statistics. The following code provides utilities for episode management.

```python
# Episode management for RL training
class HumanoidSimulation(HumanoidSimulation):

    def __init__(self, config=None):
        super().__init__(config)
        self.episode_count = 0
        self.episode_length = 0
        self.episode_reward = 0
        self.current_episode_metrics = {}
        self.max_episode_length = config.get('max_episode_length', 1000)

    def reset(self):
        """Reset the simulation and start a new episode."""
        super().reset()

        self.episode_count += 1
        self.episode_length = 0
        self.episode_reward = 0
        self.current_episode_metrics = {}

        print(f"Episode {self.episode_count} started")

        # Return initial observation
        return self.get_observation()

    def step(self, action=None):
        """
        Take a step in the environment.

        Args:
            action: Action to apply (if any)

        Returns:
            observation, reward, done, info
        """
        # Apply action if provided
        if action is not None:
            self.apply_action(action)

        # Step simulation
        super().step()

        # Get observation
        obs = self.get_observation()

        # Compute reward
        reward = self._compute_reward(obs, action)

        # Check termination
        done, termination_info = self._check_termination(obs)

        # Update episode stats
        self.episode_length += 1
        self.episode_reward += reward

        # Collect info
        info = {
            'episode': self.episode_count,
            'episode_length': self.episode_length,
            'episode_reward': self.episode_reward,
            'simulation_time': self.current_time,
            **termination_info,
        }

        if done:
            self._log_episode_info()

        return obs, reward, done, info

    def _compute_reward(self, obs, action):
        """
        Compute the reward for the current step.

        Args:
            obs: Current observation
            action: Action that was applied

        Returns:
            Scalar reward value
        """
        # Default reward - can be overridden
        return 0.0

    def _check_termination(self, obs):
        """
        Check if the episode should terminate.

        Args:
            obs: Current observation

        Returns:
            Tuple of (done, info_dict)
        """
        info = {}

        # Check timeout
        if self.episode_length >= self.max_episode_length:
            info['timeout'] = True
            return True, info

        # Check for falls (orientation outside acceptable range)
        root_state = obs.get('root_state', None)
        if root_state is not None:
            # Extract orientation (typically [3:7] in root_state)
            orientation = root_state[3:7] if len(root_state) >= 7 else None

            if orientation is not None:
                # Check if robot has fallen (simplified check)
                up_vector = self._get_up_from_quaternion(orientation)
                if up_vector[2] < 0.3:  # Robot is on side or back
                    info['fallen'] = True
                    return True, info

        return False, info

    def _get_up_from_quaternion(self, quaternion):
        """Convert quaternion to up vector."""
        # Apply quaternion rotation to (0, 0, 1)
        import numpy as np
        from scipy.spatial.transform import Rotation

        rot = Rotation.from_quat(quaternion)
        return rot.apply([0, 0, 1])

    def _log_episode_info(self):
        """Log episode completion information."""
        print(f"\nEpisode {self.episode_count} completed:")
        print(f"  Length: {self.episode_length} steps")
        print(f"  Total reward: {self.episode_reward:.4f}")
        print(f"  Avg reward/step: {self.episode_reward / max(1, self.episode_length):.4f}")

        # Log to tensorboard if configured
        if hasattr(self, 'tb_writer') and self.tb_writer:
            self.tb_writer.add_scalar('episode_reward', self.episode_reward, self.episode_count)
            self.tb_writer.add_scalar('episode_length', self.episode_length, self.episode_count)

    def get_episode_info(self):
        """Get current episode information."""
        return {
            'episode': self.episode_count,
            'length': self.episode_length,
            'reward': self.episode_reward,
            'progress': self.episode_length / self.max_episode_length,
        }
```

## Integration with External Systems

### ROS Integration

Isaac Sim can publish and subscribe to ROS topics, enabling integration with existing robotics frameworks. The following example shows how to set up ROS publishing for simulation data.

```python
# ROS integration for simulation data streaming
import omni.isaac.core.utils.ros as ros_utils
from geometry_msgs.msg import Twist, Pose, PoseArray
from sensor_msgs.msg import JointState, Image, Imu
from std_msgs.msg import Float64MultiArray
import numpy as np

class ROSHumanoidSimulation(HumanoidSimulation):
    """
    Humanoid simulation with ROS integration.
    Publishes robot state and subscribes to control commands.
    """

    def __init__(self, config=None):
        super().__init__(config)

        # ROS configuration
        self.ros_namespace = config.get('ros_namespace', '/humanoid')
        self.joint_names = config.get('joint_names', [])

        # ROS publishers and subscribers
        self.joint_state_pub = None
        self.imu_pub = None
        self.cmd_sub = None

        # Command buffer
        self.pending_commands = []

    def initialize(self, stage=None):
        """Initialize with ROS setup."""
        super().initialize(stage)

        # Set up ROS if enabled
        if self.config.get('enable_ros', True):
            self._setup_ros()

    def _setup_ros(self):
        """Set up ROS publishers and subscribers."""
        try:
            # Initialize ROS bridge
            ros_utils.initialize(self.ros_namespace)

            # Create publishers
            self.joint_state_pub = ros_utils.create_topic(
                f"{self.ros_namespace}/joint_states",
                JointState
            )

            self.imu_pub = ros_utils.create_topic(
                f"{self.ros_namespace}/imu",
                Imu
            )

            # Create subscriber for velocity commands
            self.cmd_sub = ros_utils.create_subscription(
                f"{self.ros_namespace}/cmd_vel",
                Twist,
                self._on_cmd_vel
            )

            print(f"ROS initialized with namespace: {self.ros_namespace}")

        except Exception as e:
            print(f"ROS initialization failed: {e}")
            print("Continuing without ROS")

    def _on_cmd_vel(self, msg):
        """Handle incoming velocity commands."""
        self.pending_commands.append({
            'linear': [msg.linear.x, msg.linear.y, msg.linear.z],
            'angular': [msg.angular.x, msg.angular.y, msg.angular.z],
            'timestamp': self.current_time,
        })

    def step(self, action=None):
        """
        Step simulation with ROS publishing.

        Returns:
            observation, reward, done, info
        """
        # Apply any pending ROS commands
        self._process_ros_commands()

        # Execute standard step
        obs, reward, done, info = super().step(action)

        # Publish ROS state
        if self.config.get('enable_ros', True):
            self._publish_ros_state(obs)

        return obs, reward, done, info

    def _publish_ros_state(self, obs):
        """Publish current state to ROS topics."""
        # Publish joint states
        if self.joint_state_pub is not None and obs.get('joint_positions') is not None:
            msg = JointState()
            msg.header.stamp = ros_utils.get_time_msg()
            msg.name = self.joint_names
            msg.position = obs['joint_positions'].tolist()
            msg.velocity = obs.get('joint_velocities', np.zeros(len(self.joint_names))).tolist()
            msg.effort = obs.get('joint_efforts', np.zeros(len(self.joint_names))).tolist()
            self.joint_state_pub.publish(msg)

        # Publish IMU data if available
        if self.imu_pub is not None:
            imu_data = self._get_imu_readings()
            if imu_data is not None:
                msg = Imu()
                msg.header.stamp = ros_utils.get_time_msg()
                msg.linear_acceleration.x = imu_data['accel'][0]
                msg.linear_acceleration.y = imu_data['accel'][1]
                msg.linear_acceleration.z = imu_data['accel'][2]
                msg.angular_velocity.x = imu_data['gyro'][0]
                msg.angular_velocity.y = imu_data['gyro'][1]
                msg.angular_velocity.z = imu_data['gyro'][2]
                self.imu_pub.publish(msg)

    def _process_ros_commands(self):
        """Process pending ROS commands."""
        while self.pending_commands:
            cmd = self.pending_commands.pop(0)
            # Convert cmd_vel to joint actions
            self._cmd_vel_to_joints(cmd)

    def _cmd_vel_to_joints(self, cmd):
        """Convert velocity command to joint actions."""
        # Simplified - would need actual conversion logic
        pass

    def _get_imu_readings(self):
        """Get simulated IMU readings."""
        # Would extract from IMU sensor in scene
        return None
```

## Best Practices and Performance

### Optimization Techniques

When running simulations, especially for reinforcement learning training, optimization is crucial for achieving good throughput. The following techniques can significantly improve simulation performance.

```python
# Simulation optimization techniques
class OptimizedHumanoidSimulation(HumanoidSimulation):

    def __init__( self, config=None):
        super().__init__(config)

        # Enable optimizations
        self.config.setdefault('enable_batching', True)
        self.config.setdefault('cache_observations', True)

        # Observation cache
        self._obs_cache = {}

    def get_observation(self):
        """
        Get observation with caching for efficiency.
        Only recomputes observations that have changed.
        """
        if self.config.get('cache_observations', False):
            # Check cache validity
            if self._is_cache_valid():
                return self._obs_cache.copy()

        # Compute fresh observation
        obs = super().get_observation()

        if self.config.get('cache_observations', False):
            self._obs_cache = obs

        return obs

    def _is_cache_valid(self):
        """Check if cached observation is still valid."""
        if not self._obs_cache:
            return False

        # Cache invalid if step count has changed
        return self._obs_cache.get('step') == self.current_step

    def batch_step(self, actions):
        """
        Execute multiple steps with different actions.
        Useful for generating rollout data.

        Args:
            actions: List of actions

        Returns:
            List of (observation, reward, done) tuples
        """
        results = []

        for action in actions:
            obs, reward, done, info = self.step(action)
            results.append((obs, reward, done, info))

            if done:
                obs = self.reset()

        return results

    def parallel_simulation(self, num_instances, config_modifiers=None):
        """
        Create multiple simulation instances for parallel data collection.

        Args:
            num_instances: Number of parallel simulations
            config_modifiers: List of config modifications for each instance

        Returns:
            List of simulation instances
        """
        simulations = []

        for i in range(num_instances):
            # Create instance-specific config
            instance_config = self.config.copy()

            if config_modifiers and i < len(config_modifiers):
                instance_config.update(config_modifiers[i])

            # Create new simulation instance
            sim = HumanoidSimulation(instance_config)
            simulations.append(sim)

        return simulations
```

## Connection to Capstone

The simulation loop concepts covered in this section are fundamental to the **Voice-to-Plan-to-Navigate-to-Vision-to-Manipulate** pipeline that forms the backbone of the capstone project. Here is how each component connects:

| Pipeline Stage | Simulation Loop Role |
|---------------|---------------------|
| **Voice** | The simulation loop provides the temporal framework for processing voice commands asynchronously while the robot continues executing its current motion |
| **Plan** | Episode management and state observation enable the planner to query current robot configuration and environment state for informed decision-making |
| **Navigate** | Real-time stepping with wall-clock synchronization ensures navigation commands execute at appropriate speeds, while contact detection prevents collisions |
| **Vision** | The rendering timestep configuration determines how frequently camera observations are captured; the observation tensor API provides efficient data extraction for vision models |
| **Manipulate** | Joint position/velocity/effort control through the ArticulationView API enables precise manipulation; callback registration allows coordination between grasp planning and execution |

**Key integration patterns for the capstone:**

1. **Asynchronous command processing**: Register pre-step callbacks to check for incoming voice commands without blocking physics execution
2. **Observation batching**: Use `get_observation_tensor()` to efficiently extract state for neural network inference in the planning and vision stages
3. **Episode boundaries**: Reset the simulation when the robot completes a task or encounters a failure, enabling iterative training of manipulation policies
4. **ROS bridge**: Leverage the ROS integration patterns to connect Isaac Sim with external perception and planning nodes in your capstone architecture

The `SimulationContext` class you have learned to configure here will serve as the central orchestrator, ensuring all pipeline stages receive timely state updates and can issue control commands that execute deterministically in the physics engine.

## Next Steps

With a solid understanding of the Isaac Sim simulation loop, you are ready to explore GPU-accelerated simulation techniques that can dramatically increase throughput for reinforcement learning training. The next section will cover GPU-accelerated physics, parallel environments, and optimization strategies for large-scale simulation campaigns.
