---
id: m1-c2-s7
title: Rosbag Recording, Analysis, and Replay
sidebar_position: 7
keywords: ['rosbag', 'recording', 'playback', 'debugging', 'rosbag2', 'analysis']
---

# Rosbag Recording, Analysis, and Replay

## Prerequisites

| Requirement | Description |
|-------------|-------------|
| **M1-C1-S5** | Understanding of ROS 2 topics |
| **M1-C2-S6** | QoS policies (preserved in recordings) |
| **Python** | Basic Python for analysis scripts |
| **SQLite** | Optional - understanding bag storage format |

## Learning Objectives

By the end of this section, you will be able to:

1. **Record topic data** selectively with compression and size limits
2. **Inspect bag metadata** to verify recording contents
3. **Replay bags** with rate control, topic filtering, and remapping
4. **Analyze bag contents** programmatically with Python/SQLite
5. **Extract images** from bags for dataset generation
6. **Apply rosbag workflows** for debugging, validation, and ML training

## Key Concepts

| Concept | Description | CLI Command |
|---------|-------------|-------------|
| **Recording** | Capture topic messages to SQLite | `ros2 bag record` |
| **Playback** | Replay recorded messages to topics | `ros2 bag play` |
| **Inspection** | View bag metadata and topic stats | `ros2 bag info` |
| **Compression** | Reduce bag size (zstd) | `--compression-mode file` |
| **Splitting** | Break large bags into chunks | `--max-bag-size` |

```
┌─────────────────────────────────────────────────────────────────┐
│                    Rosbag2 Data Flow                             │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│   RECORDING                                                      │
│   ─────────                                                      │
│   Live Topics ──────► ros2 bag record ──────► SQLite Database   │
│   /camera/image                               rosbag_*.db3      │
│   /imu/data                                   metadata.yaml     │
│   /joint_states                                                 │
│                                                                  │
│   PLAYBACK                                                       │
│   ────────                                                       │
│   SQLite Database ──────► ros2 bag play ──────► Replayed Topics │
│   rosbag_*.db3            --rate 2.0           /camera/image    │
│   metadata.yaml           --loop               /imu/data        │
│                           --remap              /joint_states    │
│                                                                  │
│   ANALYSIS                                                       │
│   ────────                                                       │
│   SQLite Database ──────► Python Script ──────► Statistics      │
│   rosbag_*.db3            sqlite3 API          Message counts   │
│                                                 Frequency        │
│                                                 Timeline plots   │
│                                                                  │
│   ┌─────────────────────────────────────────────────────────┐  │
│   │  Storage Format: SQLite3 (default) or MCAP              │  │
│   │  Typical Size: 10-min RGB-D @ 30Hz ≈ 15 GB uncompressed │  │
│   │  With zstd compression: ~3 GB (80% reduction)           │  │
│   └─────────────────────────────────────────────────────────┘  │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

## Overview

ROS 2 **rosbag** (rosbag2) records topic data to SQLite databases for offline analysis, deterministic replay, and dataset generation. Rosbags enable debugging race conditions, profiling perception pipelines, collecting training data, and validating algorithm changes—critical for iterative robotics development where re-running experiments on hardware is expensive.

**What You'll Build**: A complete rosbag workflow for humanoid data collection (camera + IMU + joint states), Python analysis scripts for message inspection, and replay-based perception testing.

## Hardware Requirements

**Workstation** (from M1-C1-S1)
- ROS 2 Humble installed (M1-C1-S4)
- Python 3.10+
- 50+ GB free disk space (10-minute RGB-D bag = ~15 GB)

## Connection to Capstone

The capstone uses rosbags for:

1. **Dataset Collection**: Record RGB-D + IMU during object manipulation for offline YOLO training
2. **Algorithm Validation**: Replay sensor data to test cuVSLAM without hardware
3. **Failure Analysis**: Record full system state during task failures for debugging
4. **Performance Benchmarking**: Compare perception latency across algorithm versions on identical data
5. **Sim-to-Real Transfer**: Validate that policies trained in sim generalize by replaying real sensor data

**Without Rosbags**: Every algorithm change requires re-running on hardware (time-consuming, risky). With rosbags: test changes offline in seconds.

## Implementation

### Rosbag2 Architecture

```
Topics → rosbag2 record → SQLite Database (.db3)
                          ├── metadata.yaml
                          └── rosbag2_*.db3

SQLite Database → rosbag2 play → Topics (replay)
```

**Storage Format**: SQLite3 (default), MCAP (alternative, better for large bags)

### Step 1: Recording Topics

**Record Specific Topics**:
```bash
# Record camera and IMU (Ctrl+C to stop)
ros2 bag record /camera/color/image_raw /camera/depth/image_rect_raw /imu/data

# Output: rosbag2_2025_01_15-10_30_45/
#   ├── metadata.yaml
#   └── rosbag2_2025_01_15-10_30_45_0.db3
```

**Record with Custom Name**:
```bash
ros2 bag record -o manipulation_trial_01 \
  /camera/color/image_raw /camera/depth/image_rect_raw \
  /imu/data /joint_states /gripper/state
```

**Record All Topics** (use sparingly):
```bash
ros2 bag record -a
# WARNING: High disk I/O, includes /rosout and /parameter_events
```

**Record with Compression** (50-80% size reduction):
```bash
ros2 bag record --compression-mode file --compression-format zstd \
  /camera/color/image_raw /camera/depth/image_rect_raw /imu/data
```

**Record with Duration/Size Limits**:
```bash
# Record for 60 seconds
ros2 bag record --duration 60 /camera/color/image_raw /imu/data

# Stop at 500 MB
ros2 bag record --max-bag-size 500000000 /camera/color/image_raw

# Split into 100 MB chunks
ros2 bag record --max-bag-size 100000000 --max-bag-files 10 \
  /camera/color/image_raw
```

### Step 2: Rosbag Info and Inspection

**Show Bag Metadata**:
```bash
ros2 bag info manipulation_trial_01
```

**Output**:
```
Files:             manipulation_trial_01_0.db3
Bag size:          1.2 GB
Storage id:        sqlite3
Duration:          120.456s
Start:             Jan 15 2025 10:30:45.123 (1705317045.123456789)
End:               Jan 15 2025 10:32:45.579 (1705317165.579012345)
Messages:          21805
Topic information: Topic: /camera/color/image_raw | Type: sensor_msgs/msg/Image | Count: 3600 | Serialization Format: cdr
                   Topic: /camera/depth/image_rect_raw | Type: sensor_msgs/msg/Image | Count: 3600 | Serialization Format: cdr
                   Topic: /imu/data | Type: sensor_msgs/msg/Imu | Count: 12000 | Serialization Format: cdr
                   Topic: /joint_states | Type: sensor_msgs/msg/JointState | Count: 2400 | Serialization Format: cdr
                   Topic: /gripper/state | Type: humanoid_interfaces/msg/GripperState | Count: 205 | Serialization Format: cdr
```

**Key Metrics**:
- **Message Count**: `/camera` at 30 Hz × 120s = 3600 messages ✓
- **Duration**: Actual recording time
- **Storage Format**: `sqlite3` (default), `mcap` (alternative)

### Step 3: Playback and Replay

**Basic Playback**:
```bash
ros2 bag play manipulation_trial_01
# Replays all topics at original timing
```

**Playback Options**:
```bash
# Play at 2x speed
ros2 bag play --rate 2.0 manipulation_trial_01

# Play in slow motion (0.5x)
ros2 bag play --rate 0.5 manipulation_trial_01

# Loop indefinitely
ros2 bag play --loop manipulation_trial_01

# Start from 30 seconds into bag
ros2 bag play --start-offset 30.0 manipulation_trial_01

# Play specific topics only
ros2 bag play --topics /camera/color/image_raw /imu/data manipulation_trial_01

# Remap topics during playback
ros2 bag play --remap /camera/color/image_raw:=/camera/rgb manipulation_trial_01
```

**Pause and Resume** (during playback):
- Press `Space`: Pause/Resume
- Press `s`: Step forward one message (when paused)

### Step 4: Python Bag Analysis

**File**: `~/ros2_ws/src/humanoid_control/scripts/analyze_rosbag.py`

```python
#!/usr/bin/env python3
"""
Rosbag Analysis Script
Extract statistics and visualize message timings
"""

import sqlite3
import yaml
from pathlib import Path
import matplotlib.pyplot as plt
from collections import defaultdict

class RosbagAnalyzer:
    def __init__(self, bag_path):
        self.bag_path = Path(bag_path)
        self.metadata = self._load_metadata()
        self.db_path = self._find_db_file()

    def _load_metadata(self):
        """Load metadata.yaml"""
        metadata_file = self.bag_path / 'metadata.yaml'
        with open(metadata_file, 'r') as f:
            return yaml.safe_load(f)

    def _find_db_file(self):
        """Find SQLite database file"""
        db_files = list(self.bag_path.glob('*.db3'))
        if not db_files:
            raise FileNotFoundError(f'No .db3 files in {self.bag_path}')
        return db_files[0]

    def get_topic_stats(self):
        """Compute message count and frequency per topic"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        # Get topic metadata
        cursor.execute('SELECT id, name, type FROM topics')
        topics = {row[0]: {'name': row[1], 'type': row[2]} for row in cursor.fetchall()}

        # Count messages per topic
        stats = defaultdict(lambda: {'count': 0, 'timestamps': []})

        cursor.execute('SELECT topic_id, timestamp FROM messages ORDER BY timestamp')
        for row in cursor.fetchall():
            topic_id, timestamp = row
            topic_name = topics[topic_id]['name']
            stats[topic_name]['count'] += 1
            stats[topic_name]['timestamps'].append(timestamp / 1e9)  # Convert to seconds

        conn.close()

        # Compute frequencies
        for topic, data in stats.items():
            if len(data['timestamps']) > 1:
                duration = data['timestamps'][-1] - data['timestamps'][0]
                data['frequency'] = data['count'] / duration if duration > 0 else 0
            else:
                data['frequency'] = 0

            # Compute inter-message intervals
            if len(data['timestamps']) > 1:
                intervals = [data['timestamps'][i+1] - data['timestamps'][i]
                            for i in range(len(data['timestamps'])-1)]
                data['avg_interval'] = sum(intervals) / len(intervals)
                data['max_interval'] = max(intervals)
            else:
                data['avg_interval'] = 0
                data['max_interval'] = 0

        return stats

    def print_summary(self):
        """Print bag summary"""
        print(f"\n{'='*70}")
        print(f"Rosbag Analysis: {self.bag_path.name}")
        print(f"{'='*70}\n")

        stats = self.get_topic_stats()

        print(f"{'Topic':<40} {'Count':<10} {'Freq (Hz)':<12} {'Max Gap (ms)':<15}")
        print(f"{'-'*70}")

        for topic, data in sorted(stats.items()):
            print(f"{topic:<40} {data['count']:<10} {data['frequency']:<12.2f} {data['max_interval']*1000:<15.2f}")

    def plot_message_timeline(self):
        """Visualize message arrival times"""
        stats = self.get_topic_stats()

        fig, ax = plt.subplots(figsize=(12, 6))

        for i, (topic, data) in enumerate(sorted(stats.items())):
            timestamps = data['timestamps']
            # Normalize to start at 0
            timestamps = [t - timestamps[0] for t in timestamps]
            ax.scatter(timestamps, [i] * len(timestamps), s=1, label=topic)

        ax.set_yticks(range(len(stats)))
        ax.set_yticklabels(sorted(stats.keys()))
        ax.set_xlabel('Time (seconds)')
        ax.set_title('Message Timeline')
        ax.legend(loc='upper right', fontsize=8)
        plt.tight_layout()
        plt.savefig('rosbag_timeline.png', dpi=150)
        print(f"\nSaved timeline plot to rosbag_timeline.png")
        plt.show()


def main():
    import sys

    if len(sys.argv) < 2:
        print("Usage: python3 analyze_rosbag.py <bag_directory>")
        print("Example: python3 analyze_rosbag.py manipulation_trial_01")
        sys.exit(1)

    bag_path = sys.argv[1]
    analyzer = RosbagAnalyzer(bag_path)
    analyzer.print_summary()
    analyzer.plot_message_timeline()


if __name__ == '__main__':
    main()
```

**Run Analysis**:
```bash
python3 analyze_rosbag.py manipulation_trial_01
```

**Expected Output**:
```
======================================================================
Rosbag Analysis: manipulation_trial_01
======================================================================

Topic                                    Count      Freq (Hz)    Max Gap (ms)
----------------------------------------------------------------------
/camera/color/image_raw                  3600       29.97        45.23
/camera/depth/image_rect_raw             3600       29.97        43.89
/imu/data                                12000      99.63        11.02
/joint_states                            2400       19.93        52.10
/gripper/state                           205        1.70         5120.45

Saved timeline plot to rosbag_timeline.png
```

### Step 5: Extract Images from Rosbag

**File**: `~/ros2_ws/src/humanoid_control/scripts/extract_images.py`

```python
#!/usr/bin/env python3
"""
Extract images from rosbag to files
For offline dataset generation and labeling
"""

import rclpy
from rclpy.node import Node
from rclpy.serialization import deserialize_message
from sensor_msgs.msg import Image
from cv_bridge import CvBridge
import cv2
import sqlite3
from pathlib import Path
import yaml

class ImageExtractor:
    def __init__(self, bag_path, output_dir, topic_name):
        self.bag_path = Path(bag_path)
        self.output_dir = Path(output_dir)
        self.topic_name = topic_name
        self.bridge = CvBridge()

        self.output_dir.mkdir(parents=True, exist_ok=True)

        self.db_path = list(self.bag_path.glob('*.db3'))[0]
        self.metadata = self._load_metadata()

    def _load_metadata(self):
        metadata_file = self.bag_path / 'metadata.yaml'
        with open(metadata_file, 'r') as f:
            return yaml.safe_load(f)

    def extract(self):
        """Extract all images from topic"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        # Get topic ID
        cursor.execute('SELECT id FROM topics WHERE name = ?', (self.topic_name,))
        result = cursor.fetchone()
        if not result:
            print(f"Topic {self.topic_name} not found in bag")
            return

        topic_id = result[0]

        # Get all messages for this topic
        cursor.execute('SELECT timestamp, data FROM messages WHERE topic_id = ? ORDER BY timestamp', (topic_id,))

        frame_count = 0
        for row in cursor.fetchall():
            timestamp, data = row

            # Deserialize message
            msg = deserialize_message(data, Image)

            # Convert to OpenCV image
            cv_image = self.bridge.imgmsg_to_cv2(msg, desired_encoding='bgr8')

            # Save image
            filename = self.output_dir / f'frame_{frame_count:06d}_{timestamp}.png'
            cv2.imwrite(str(filename), cv_image)

            frame_count += 1

            if frame_count % 100 == 0:
                print(f'Extracted {frame_count} frames...')

        conn.close()
        print(f'\nExtracted {frame_count} frames to {self.output_dir}')


def main():
    import sys

    if len(sys.argv) < 4:
        print("Usage: python3 extract_images.py <bag_dir> <output_dir> <topic>")
        print("Example: python3 extract_images.py manipulation_trial_01 ./images /camera/color/image_raw")
        sys.exit(1)

    bag_path = sys.argv[1]
    output_dir = sys.argv[2]
    topic = sys.argv[3]

    extractor = ImageExtractor(bag_path, output_dir, topic)
    extractor.extract()


if __name__ == '__main__':
    main()
```

**Extract Images**:
```bash
python3 extract_images.py manipulation_trial_01 ./dataset/images /camera/color/image_raw
# Creates: dataset/images/frame_000000_*.png, frame_000001_*.png, ...
```

### Step 6: Selective Topic Recording Script

**File**: `static/code/record_manipulation_bag.sh`

```bash
#!/bin/bash
# Record manipulation dataset with optimal QoS and compression
# Usage: ./record_manipulation_bag.sh <trial_name> <duration_seconds>

set -e

TRIAL_NAME=${1:-"manipulation_trial"}
DURATION=${2:-120}

TOPICS=(
    "/camera/color/image_raw"
    "/camera/depth/image_rect_raw"
    "/camera/color/camera_info"
    "/camera/depth/camera_info"
    "/imu/data"
    "/joint_states"
    "/gripper/state"
    "/tf"
    "/tf_static"
)

OUTPUT_DIR="$HOME/rosbags/${TRIAL_NAME}_$(date +%Y%m%d_%H%M%S)"
mkdir -p "$OUTPUT_DIR"

echo "===== Recording Manipulation Bag ====="
echo "Output: $OUTPUT_DIR"
echo "Duration: ${DURATION}s"
echo "Topics: ${#TOPICS[@]}"
echo ""

# Record with compression
ros2 bag record \
    --output "$OUTPUT_DIR" \
    --duration "$DURATION" \
    --compression-mode file \
    --compression-format zstd \
    "${TOPICS[@]}"

echo ""
echo "===== Recording Complete ====="
echo "Bag saved to: $OUTPUT_DIR"

# Show bag info
ros2 bag info "$OUTPUT_DIR"
```

**Make Executable**:
```bash
chmod +x record_manipulation_bag.sh
```

**Record Dataset**:
```bash
./record_manipulation_bag.sh grasp_red_block 60
# Records 60-second bag with all necessary topics
```

## Rosbag Best Practices

### 1. Topic Selection

```bash
# Good: Only record necessary topics
ros2 bag record /camera/color/image_raw /imu/data /joint_states

# Bad: Record everything (includes /rosout spam)
ros2 bag record -a
```

### 2. Compression

```bash
# Always compress image/pointcloud data
ros2 bag record --compression-mode file --compression-format zstd \
  /camera/color/image_raw /camera/depth/image_rect_raw

# Result: 15 GB uncompressed → 3 GB compressed (80% reduction)
```

### 3. Include TF

```bash
# Always record TF for spatial transforms
ros2 bag record /camera/image /imu/data /tf /tf_static
# Without /tf, cannot transform camera poses to base_link
```

### 4. Split Large Bags

```bash
# Split into 1 GB chunks for easier handling
ros2 bag record --max-bag-size 1000000000 --max-bag-files 20 \
  /camera/color/image_raw
```

### 5. Metadata Annotation

Create `bag_metadata.yaml` alongside bag:
```yaml
trial_name: "grasp_red_block_trial_05"
date: "2025-01-15"
location: "Lab 3, Workstation B"
robot_id: "unitree_g1_01"
task: "Pick and place red block"
notes: |
  - Successful grasp after 2 attempts
  - Object slipped during lift phase (see timestamp 45.2s)
  - Re-grasped with increased force (50N → 60N)
topics:
  /camera/color/image_raw: "RGB images at 30 Hz"
  /camera/depth/image_rect_raw: "Aligned depth at 30 Hz"
  /imu/data: "IMU readings at 100 Hz"
  /joint_states: "Arm joint angles at 20 Hz"
  /gripper/state: "Gripper force feedback at 1 Hz"
```

## Common Rosbag Workflows

### Workflow 1: Dataset Collection for YOLO Training

```bash
# 1. Record manipulation trials (10 trials × 60s each)
for i in {1..10}; do
    ./record_manipulation_bag.sh trial_$i 60
    sleep 5  # Wait between trials
done

# 2. Extract images
for trial in ~/rosbags/trial_*; do
    python3 extract_images.py "$trial" "./dataset/images_$trial" /camera/color/image_raw
done

# 3. Label images (manual or LabelImg)
labelImg ./dataset/images_trial_*/

# 4. Train YOLO
python3 train_yolo.py --data ./dataset --epochs 100
```

### Workflow 2: Perception Algorithm Validation

```bash
# 1. Record baseline with current algorithm
ros2 bag record -o baseline /camera/color/image_raw /detected_objects

# 2. Develop improved algorithm

# 3. Replay bag and record new detections
ros2 bag play baseline &
ros2 bag record -o improved /detected_objects

# 4. Compare detection metrics
python3 compare_detections.py baseline improved
```

### Workflow 3: Failure Analysis

```bash
# 1. Reproduce failure on hardware
ros2 bag record -a  # Record everything during failure

# 2. Offline debugging
ros2 bag play failure_2025_01_15 --rate 0.1  # Slow motion replay

# 3. Step through messages
ros2 bag play failure_2025_01_15 --pause
# Press 's' to step through messages one-by-one
```

## Next Steps

**Chapter 2 Complete!** Proceed to:
- **M1-C3-S1**: URDF Basics (robot description for visualization and kinematics)
- **M1-C3-S2**: Xacro and Parametric URDF (modular robot descriptions)
- **M1-C3-S3**: Forward Kinematics (compute end-effector pose from joint angles)

**Troubleshooting**:
- **Bag file too large**: Use compression and split into chunks
- **Playback drops messages**: Reduce playback rate with `--rate 0.5`
- **Cannot extract images**: Install `cv_bridge`: `sudo apt install ros-kilted-cv-bridge python3-opencv`
- **Corrupted bag**: Check with `sqlite3 <bag>.db3 "PRAGMA integrity_check;"`

**Real-World Rosbag Examples**:
- KITTI Dataset: Autonomous driving bags (lidar, camera, GPS)
- RoboTurk: Teleoperation demonstrations for imitation learning
- Isaac Sim: Synthetic data generation with ground truth labels

---

**Assessment Preparation**: This section is **ESSENTIAL** for **Assessment 1: ROS 2 Fundamentals Quiz (Week 3)**. You must demonstrate recording, analyzing, and replaying rosbags for debugging and dataset generation.

**Module 1, Chapter 2: COMPLETE** ✅
