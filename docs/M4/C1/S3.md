---
id: m4-c1-s3
title: Natural Language Parsing
sidebar_position: 3
keywords: ['nlp', 'parsing', 'intent', 'language']
---

# Natural Language Parsing

## Prerequisites

Before diving into this section, you should be familiar with:

- **Python programming fundamentals** including classes, dataclasses, and type hints
- **Regular expressions (regex)** for pattern matching in text
- **Speech-to-Text concepts** from Section S2, understanding how audio is transcribed to text
- **Basic NLP terminology** such as tokens, parsing, and text preprocessing
- **Data structures** including dictionaries, lists, and enums in Python

## Learning Objectives

By the end of this section, you will be able to:

| Level | Objective |
|-------|-----------|
| **[Beginner]** | Define intent recognition and explain its role in robot command processing |
| **[Beginner]** | Identify the key components of a parsed command (intent, entities, confidence) |
| **[Intermediate]** | Implement a pattern-based intent recognizer using regular expressions |
| **[Intermediate]** | Configure entity extraction patterns for common robot interaction scenarios |
| **[Intermediate]** | Build an entity linker to connect parsed entities to a knowledge base |
| **[Advanced]** | Architect a complete NLP pipeline that validates and completes ambiguous commands |
| **[Advanced]** | Optimize semantic role labeling for complex multi-step robot instructions |

## Key Concepts

| Term | Definition |
|------|------------|
| **Intent** | The underlying goal or purpose of a user's command (e.g., navigate, manipulate, question) |
| **Entity** | A named piece of information extracted from text, such as locations, objects, or people |
| **Entity Linking** | The process of connecting extracted entities to entries in a knowledge base |
| **Semantic Role** | The function a word or phrase plays in a sentence (agent, theme, location, manner) |
| **Confidence Score** | A numerical value (0-1) indicating the certainty of intent or entity classification |
| **Knowledge Base** | A structured database of known objects, locations, and their properties for entity resolution |
| **Command Validation** | Checking parsed commands for completeness and required parameters before execution |
| **Synonym Mapping** | Converting equivalent words to canonical forms (e.g., "grab" → "pick") |

:::danger Latency Trap Warning
**NLP parsing MUST run locally for real-time interaction.** Cloud NLP APIs add 100-300ms latency per request, making conversations feel sluggish:
- Use local regex/pattern matching for common intents
- Deploy lightweight transformer models (DistilBERT) on Jetson for complex parsing
- Reserve cloud NLU for non-interactive batch processing only
:::

---

Natural language parsing extracts meaning and intent from transcribed speech, enabling humanoid robots to understand human commands. This section covers intent recognition, entity extraction, and dialogue act classification for robot interaction.

For humanoid robots, robust language understanding is essential for translating natural commands into executable robot actions.

## Intent Recognition

### Understanding User Commands

```python
# Natural language parsing for robot commands
import re
import json
from typing import Dict, List, Tuple, Optional, Set
from dataclasses import dataclass, field
from enum import Enum
from collections import defaultdict
import numpy as np

class IntentType(Enum):
    """Intent types for robot commands."""
    NAVIGATE = "navigate"
    MANIPULATE = "manipulate"
    CONVERSE = "converse"
    QUESTION = "question"
    COMMAND = "command"
    REQUEST_INFO = "request_info"
    GREETING = "greeting"
    CONFIRMATION = "confirmation"
    NEGATION = "negation"
    UNKNOWN = "unknown"


@dataclass
class Entity:
    """Named entity extracted from text."""
    type: str
    value: str
    start: int
    end: int
    confidence: float = 1.0


@dataclass
class ParsedCommand:
    """Parsed natural language command."""
    intent: IntentType
    entities: List[Entity]
    raw_text: str
    confidence: float
    action_params: Dict = field(default_factory=dict)
    context: Dict = field(default_factory=dict)


class IntentRecognizer:
    """
    Intent recognition system for robot commands.
    Uses pattern matching and keyword extraction.
    """

    def __init__(self):
        """Initialize intent recognizer."""
        # Intent patterns (regex-based)
        self.intent_patterns = {
            IntentType.NAVIGATE: [
                r'(?:go|move|walk|navigate)\s+(?:to|to the)?\s*(\w+)',
                r'(?:take me|bring me)\s+(?:to|to the)?\s*(\w+)',
                r'(?:where is|find)\s+(\w+)',
                r'(?:come here|come to me)',
            ],
            IntentType.MANIPULATE: [
                r'(?:pick|grab|take)\s+(?:up|the)?\s*(\w+)',
                r'(?:put|place|set|drop)\s+(?:down|the)?\s*(\w+)',
                r'(?:hand|give)\s+(?:me|to me)?\s*(\w+)',
                r'(?:open|close)\s+(?:the)?\s*(\w+)',
                r'(?:turn|switch)\s+(?:on|off)?\s*(\w+)',
            ],
            IntentType.CONVERSE: [
                r'(?:tell|show)\s+(?:me)?\s*(?:about)?\s*(\w+)',
                r'(?:what is|what\'s|who is)\s+(\w+)',
                r'(?:explain|describe)\s+(\w+)',
            ],
            IntentType.GREETING: [
                r'(?:hello|hi|hey|greetings)',
                r'(?:good morning|good afternoon|good evening)',
            ],
            IntentType.CONFIRMATION: [
                r'(?:yes|yeah|sure|ok|okay|agree|correct)',
            ],
            IntentType.NEGATION: [
                r'(?:no|nope|not|don\'t|never|disagree)',
            ],
            IntentType.QUESTION: [
                r'(?:\?|how|what|when|where|why|which)',
                r'can you\s+\w+',
            ],
        }

        # Entity patterns
        self.entity_patterns = {
            'LOCATION': [
                r'(?:kitchen|living room|bedroom|bathroom|office|hallway|garage)',
                r'(?:here|there|over there)',
            ],
            'OBJECT': [
                r'(?:cup|glass|bottle|plate|phone|book|remote)',
                r'(?:the )?\w+(?:s)?',
            ],
            'PERSON': [
                r'(?:me|my|myself)',
                r'(?:mom|dad|brother|sister|friend)',
            ],
            'ACTION': [
                r'(?:pick|grab|put|give|bring|take|move|go)',
            ],
            'DIRECTION': [
                r'(?:left|right|forward|backward|back|up|down)',
            ],
            'QUANTITY': [
                r'\d+(?:\.\d+)?',
                r'(?:one|two|three|four|five|half|quarter)',
            ],
        }

        # Synonym mappings
        self.synonyms = {
            'grab': 'pick',
            'fetch': 'pick',
            'bring': 'give',
            'toss': 'throw',
            'head': 'go',
            'walk': 'go',
            'locate': 'find',
        }

    def parse(self, text: str) -> ParsedCommand:
        """
        Parse natural language command.

        Args:
            text: Input text

        Returns:
            ParsedCommand with intent and entities
        """
        # Preprocess
        text_lower = text.lower().strip()

        # Remove punctuation
        text_clean = re.sub(r'[^\w\s]', '', text_lower)

        # Detect intent
        intent, intent_confidence = self._detect_intent(text_clean)

        # Extract entities
        entities = self._extract_entities(text_clean)

        # Build action parameters
        action_params = self._extract_action_params(intent, entities, text_clean)

        return ParsedCommand(
            intent=intent,
            entities=entities,
            raw_text=text,
            confidence=intent_confidence,
            action_params=action_params
        )

    def _detect_intent(self, text: str) -> Tuple[IntentType, float]:
        """Detect intent from text."""
        best_intent = IntentType.UNKNOWN
        best_confidence = 0.0

        for intent, patterns in self.intent_patterns.items():
            for pattern in patterns:
                match = re.search(pattern, text, re.IGNORECASE)
                if match:
                    # Calculate confidence based on match quality
                    match_ratio = len(match.group(0)) / max(len(text), 1)
                    confidence = min(0.5 + match_ratio, 0.95)

                    if confidence > best_confidence:
                        best_intent = intent
                        best_confidence = confidence

        return best_intent, best_confidence

    def _extract_entities(self, text: str) -> List[Entity]:
        """Extract named entities from text."""
        entities = []

        for entity_type, patterns in self.entity_patterns.items():
            for pattern in patterns:
                for match in re.finditer(pattern, text, re.IGNORECASE):
                    entity = Entity(
                        type=entity_type,
                        value=match.group(0),
                        start=match.start(),
                        end=match.end(),
                        confidence=0.8
                    )
                    entities.append(entity)

        # Remove overlapping entities (keep highest confidence)
        entities = self._remove_overlapping(entities)

        return entities

    def _remove_overlapping(self, entities: List[Entity]) -> List[Entity]:
        """Remove overlapping entities."""
        sorted_entities = sorted(entities, key=lambda e: (-e.confidence, e.start))

        non_overlapping = []
        for entity in sorted_entities:
            overlaps = False
            for existing in non_overlapping:
                if (entity.start < existing.end and entity.end > existing.start):
                    overlaps = True
                    break
            if not overlaps:
                non_overlapping.append(entity)

        return non_overlapping

    def _extract_action_params(self, intent: IntentType,
                                entities: List[Entity],
                                text: str) -> Dict:
        """Extract action parameters based on intent."""
        params = {}

        # Create entity lookup
        entity_by_type = defaultdict(list)
        for entity in entities:
            entity_by_type[entity.type].append(entity.value)

        if intent == IntentType.NAVIGATE:
            locations = entity_by_type.get('LOCATION', [])
            if locations:
                params['destination'] = locations[0]
            else:
                # Try to extract from context
                params['destination'] = 'unknown'

        elif intent == IntentType.MANIPULATE:
            objects = entity_by_type.get('OBJECT', [])
            if objects:
                params['object'] = objects[0]

            actions = entity_by_type.get('ACTION', [])
            if actions:
                # Normalize action
                action = actions[0].lower()
                params['action'] = self.synonyms.get(action, action)

        elif intent == IntentType.QUESTION:
            params['question_type'] = 'wh'  # what, how, where, etc.

        return params


class EntityLinker:
    """
    Link extracted entities to robot knowledge base.
    Resolves references to real-world objects and locations.
    """

    def __init__(self, knowledge_base: Dict = None):
        """Initialize entity linker."""
        # Knowledge base of known objects and locations
        self.knowledge_base = knowledge_base or self._default_knowledge_base()

    def _default_knowledge_base(self) -> Dict:
        """Get default knowledge base."""
        return {
            'locations': {
                'kitchen': {'x': 5.0, 'y': 3.0, 'description': 'Kitchen area'},
                'living room': {'x': 0.0, 'y': 0.0, 'description': 'Main living area'},
                'bedroom': {'x': -3.0, 'y': 2.0, 'description': 'Master bedroom'},
                'bathroom': {'x': 3.0, 'y': -2.0, 'description': 'Bathroom'},
                'office': {'x': -2.0, 'y': -1.0, 'description': 'Home office'},
            },
            'objects': {
                'cup': {'type': 'container', 'grasp_point': 'top'},
                'bottle': {'type': 'container', 'grasp_point': 'body'},
                'phone': {'type': 'electronics', 'grasp_point': 'any'},
                'book': {'type': 'reading_material', 'grasp_point': 'spine'},
                'remote': {'type': 'controller', 'grasp_point': 'body'},
            },
            'people': {
                'me': {'relation': 'user'},
                'mom': {'relation': 'family'},
                'dad': {'relation': 'family'},
            }
        }

    def link_entity(self, entity: Entity) -> Dict:
        """
        Link entity to knowledge base.

        Args:
            entity: Extracted entity

        Returns:
            Linked entity with resolved info
        """
        value = entity.value.lower()

        # Check each category
        for category, items in self.knowledge_base.items():
            if value in items:
                return {
                    'original': entity,
                    'linked_type': category,
                    'linked_value': value,
                    'properties': items[value],
                    'confidence': 0.9
                }

        # Partial matching
        for category, items in self.knowledge_base.items():
            for key, props in items.items():
                if value in key or key in value:
                    return {
                        'original': entity,
                        'linked_type': category,
                        'linked_value': key,
                        'properties': props,
                        'confidence': 0.7
                    }

        return {
            'original': entity,
            'linked_type': 'unknown',
            'linked_value': value,
            'properties': {},
            'confidence': 0.3
        }

    def link_all(self, entities: List[Entity]) -> List[Dict]:
        """Link all entities in a command."""
        return [self.link_entity(e) for e in entities]
```

## Semantic Role Labeling

### Understanding Command Structure

```python
# Semantic role labeling for robot commands
from typing import Dict, List, Tuple
from dataclasses import dataclass

@dataclass
class SemanticRole:
    """Semantic role in a command."""
    role: str  # agent, patient, theme, location, etc.
    text: str
    span: Tuple[int, int]


class SemanticRoleLabeler:
    """
    Label semantic roles in robot commands.
    Identifies who does what to whom, where, and when.
    """

    def __init__(self):
        """Initialize role labeler."""
        # Role patterns
        self.role_patterns = {
            'AGENT': [
                (r'^(\w+)\s+(?:will|shall|must|should|can)\s+', 'subject'),
                (r'(?:you|robot)\s+(?:must|should|need to|have to)\s+', 'agent'),
            ],
            'THEME': [
                (r'(?:the|a|an)?\s*(\w+)\s+(?:that|which|what)\s+', 'object'),
                (r'pick\s+(?:up)?\s*(?:the)?\s*(\w+)', 'object'),
                (r'put\s+(?:down)?\s*(?:the)?\s*(\w+)', 'object'),
            ],
            'LOCATION': [
                (r'(?:to|in|at|on)\s+(?:the)?\s*(\w+)', 'destination'),
                (r'(?:kitchen|living room|bedroom|bathroom|office)', 'named_location'),
            ],
            'MANNER': [
                (r'(?:quickly|slowly|carefully|gently)', 'speed'),
                (r'(?:with|using)\s+(?:the)?\s*(\w+)', 'instrument'),
            ],
        }

    def label(self, text: str) -> List[SemanticRole]:
        """
        Label semantic roles in text.

        Args:
            text: Input text

        Returns:
            List of SemanticRole objects
        """
        roles = []

        for role, patterns in self.role_patterns.items():
            for pattern, role_type in patterns:
                for match in re.finditer(pattern, text, re.IGNORECASE):
                    if match.lastindex:
                        value = match.group(1)
                    else:
                        value = match.group(0)

                    roles.append(SemanticRole(
                        role=role,
                        text=value,
                        span=(match.start(), match.end())
                    ))

        return roles


class CommandValidator:
    """
    Validate parsed commands for completeness and validity.
    Checks if required parameters are present.
    """

    def __init__(self, knowledge_base: Dict = None):
        """Initialize validator."""
        self.knowledge_base = knowledge_base or {}

        # Intent requirements
        self.intent_requirements = {
            IntentType.NAVIGATE: ['LOCATION'],
            IntentType.MANIPULATE: ['OBJECT', 'ACTION'],
            IntentType.CONVERSE: ['TOPIC'],
        }

    def validate(self, parsed: ParsedCommand) -> Dict:
        """
        Validate parsed command.

        Args:
            parsed: Parsed command

        Returns:
            Validation result with errors/warnings
        """
        result = {
            'valid': True,
            'errors': [],
            'warnings': [],
            'missing_entities': []
        }

        # Check intent-specific requirements
        required = self.intent_requirements.get(parsed.intent, [])

        entity_types = {e.type for e in parsed.entities}

        for req_entity in required:
            if req_entity not in entity_types:
                result['valid'] = False
                result['missing_entities'].append(req_entity)
                result['errors'].append(f"Missing required entity: {req_entity}")

        # Check entity validity
        for entity in parsed.entities:
            if entity.type == 'LOCATION':
                if entity.value.lower() not in self.knowledge_base.get('locations', {}):
                    result['warnings'].append(f"Unknown location: {entity.value}")

        return result

    def suggest_completion(self, parsed: ParsedCommand) -> str:
        """
        Suggest how to complete incomplete command.

        Args:
            parsed: Parsed command

        Returns:
            Suggestion string
        """
        result = self.validate(parsed)

        if not result['missing_entities']:
            return "Command appears complete."

        missing = result['missing_entities'][0]

        suggestions = {
            'LOCATION': "Where would you like to go? (e.g., kitchen, living room)",
            'OBJECT': "What object would you like to interact with?",
            'ACTION': "What action should I perform?",
        }

        return suggestions.get(missing, f"Please specify the {missing}.")
```

## Connection to Capstone

The Natural Language Parsing module is a critical bridge in the **Voice → Plan → Navigate → Vision → Manipulate** pipeline:

| Pipeline Stage | How NLP Enables It |
|----------------|-------------------|
| **Voice → Plan** | The `IntentRecognizer` transforms raw transcribed speech into structured `ParsedCommand` objects with identified intents (NAVIGATE, MANIPULATE, etc.) and extracted entities, providing the semantic foundation for task planning |
| **Plan → Navigate** | When `IntentType.NAVIGATE` is detected, the `EntityLinker` resolves location entities (e.g., "kitchen") to coordinates from the knowledge base, enabling the navigation planner to generate waypoints |
| **Plan → Manipulate** | For `IntentType.MANIPULATE`, extracted OBJECT and ACTION entities map directly to manipulation primitives (pick, place, hand), with the knowledge base providing grasp points and object properties |
| **Context Management** | The `CommandValidator` ensures commands are complete before execution, using `suggest_completion()` to request missing information—preventing failed robot actions |
| **Semantic Understanding** | `SemanticRoleLabeler` identifies WHO does WHAT to WHOM, WHERE, and HOW—enabling complex multi-step instructions like "carefully pick up the cup from the kitchen and bring it to me" |

In your capstone project, the NLP module will receive transcribed text from the Speech-to-Text system (S2) and output structured commands that drive both navigation (M3) and manipulation (M5) subsystems. The confidence scores allow the robot to request clarification when commands are ambiguous, creating a more robust human-robot interaction loop.

## Next Steps

With Natural Language Parsing covered, you can now understand user intent from speech. The next section explores Multimodal Sensor Fusion for combining speech with visual and gestural input.
