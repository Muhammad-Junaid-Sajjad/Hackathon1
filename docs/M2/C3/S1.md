---
id: m2-c3-s1
title: Real-to-Sim Parameter Estimation
sidebar_position: 1
keywords: ['parameter-estimation', 'real-to-sim', 'system-identification', 'calibration', 'optimization', 'allan-variance', 'sensor-calibration']
---

# Real-to-Sim Parameter Estimation

## Prerequisites

Before starting this section, ensure you have:

| Prerequisite | Description | Verification |
|-------------|-------------|--------------|
| **M2-C2-S4** | IMU noise models and Allan variance | Understand IMU noise characteristics |
| **M2-C2-S7** | Synthetic data generation basics | Can generate training datasets |
| **Python 3.11+** | With SciPy, NumPy, OpenCV | `python3 -c "import scipy, cv2"` |
| **Linear Algebra** | Matrix operations, least squares | Comfortable with optimization |
| **Calibration Hardware** | Checkerboard/ChArUco board | Physical calibration target |

## Learning Objectives

By the end of this section, you will be able to:

| Level | Objectives |
|-------|-----------|
| **ðŸŒ± Beginner** | Explain why real-to-sim parameter estimation matters |
| | Understand the difference between forward (sim) and inverse (real-to-sim) problems |
| | Collect stationary IMU data for bias estimation |
| **ðŸ”§ Intermediate** | Implement camera intrinsic calibration from checkerboard images |
| | Estimate IMU bias and noise parameters using Allan variance |
| | Use optimization to fit simulation parameters to real data |
| **âš¡ Advanced** | Design robust parameter estimation pipelines with uncertainty quantification |
| | Implement bootstrap and cross-validation for parameter confidence |
| | Handle multi-sensor calibration with extrinsic estimation |
| **ðŸ—ï¸ Architect** | Design enterprise calibration infrastructure for robot fleets |
| | Integrate parameter estimation into CI/CD for simulation fidelity |
| | Architect agentic systems that self-calibrate from operational data |

## Key Concepts

| Term | Definition | Why It Matters |
|------|------------|----------------|
| **Real-to-Sim** | Inferring simulation parameters from real sensor data | Grounds simulation in measured hardware behavior |
| **System Identification** | Process of building mathematical models from data | Foundation for accurate simulation |
| **Intrinsic Calibration** | Estimating internal camera parameters | Required for accurate projection |
| **Extrinsic Calibration** | Estimating sensor-to-sensor transforms | Enables multi-sensor fusion |
| **Allan Variance** | Statistical method for characterizing noise | Standard for IMU noise analysis |
| **Bias Instability** | Slow drift in sensor bias over time | Limits long-term accuracy |
| **Noise Density** | White noise magnitude per âˆšHz | Determines short-term precision |
| **Reprojection Error** | Pixel distance between projected and measured | Key calibration quality metric |
| **Bootstrap Estimation** | Resampling for uncertainty quantification | Provides confidence intervals |

## Skill-Level Pathways

:::note Beginner Path ðŸŒ±
If you're new to parameter estimation, focus on:
1. Understanding **why** simulation parameters must match real hardware
2. Collecting stationary IMU data and computing simple bias
3. Running the checkerboard camera calibration example
4. Completing Exercise 1

Skip the optimization and uncertainty quantification sections on first read.
:::

:::tip Intermediate Path ðŸ”§
If you have calibration experience, focus on:
1. Allan variance analysis for IMU characterization
2. Optimization-based parameter fitting
3. Parameter validation and comparison
4. Exercises 1-2
:::

:::caution Advanced Path âš¡
For production calibration systems, pay attention to:
1. Uncertainty quantification with bootstrap/cross-validation
2. Multi-sensor extrinsic calibration
3. Automated calibration pipelines
4. Exercise 3 (Production Challenge)
:::

---

## Overview

**Real-to-sim parameter estimation** reverses the simulation process: instead of configuring simulation parameters and hoping they match reality, we collect real-world sensor data and infer the simulation parameters that would produce similar observations. This system identification approach closes the sim-to-real gap by ensuring simulation parameters are grounded in measured hardware behavior.

:::note For Beginners ðŸŒ±
**The Forward vs Inverse Problem**:
- **Forward (Simulation)**: Given parameters â†’ compute outputs
- **Inverse (Real-to-Sim)**: Given outputs â†’ infer parameters

It's like:
- Forward: "If I know the recipe, what dish do I get?"
- Inverse: "Given the dish, what was the recipe?"

The inverse problem is harder because multiple parameter combinations might produce similar outputs.
:::

**What You'll Build**: Complete parameter estimation pipeline that takes real sensor data and outputs calibrated simulation parameters for:
- Camera intrinsics (focal length, principal point, distortion)
- IMU parameters (bias, scale factors, noise characteristics)
- Physics parameters (mass, friction, damping)

---

## The Parameter Estimation Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    REAL-TO-SIM PARAMETER ESTIMATION                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚   Real       â”‚â”€â”€â”€â–¶â”‚   Feature    â”‚â”€â”€â”€â–¶â”‚   Parameter  â”‚               â”‚
â”‚  â”‚   Sensor     â”‚    â”‚   Extract    â”‚    â”‚   Estimate   â”‚               â”‚
â”‚  â”‚   Data       â”‚    â”‚              â”‚    â”‚              â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚        â”‚                    â”‚                    â”‚                       â”‚
â”‚        â–¼                    â–¼                    â–¼                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚   Camera:    â”‚    â”‚   Corners,   â”‚    â”‚   Intrinsics â”‚               â”‚
â”‚  â”‚   Images     â”‚    â”‚   Points,    â”‚    â”‚   Distortion â”‚               â”‚
â”‚  â”‚   IMU: Raw   â”‚    â”‚   Statistics â”‚    â”‚   Bias/Noise â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                                 â”‚                        â”‚
â”‚                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚                            â–¼                                         â–¼  â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚                    â”‚  Uncertainty â”‚                        â”‚  Export  â”‚ â”‚
â”‚                    â”‚  Quantify    â”‚                        â”‚  Config  â”‚ â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                            â”‚                                     â”‚      â”‚
â”‚                            â–¼                                     â–¼      â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚                    â”‚   Validate   â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  Gazebo  â”‚ â”‚
â”‚                    â”‚   Against GT â”‚                        â”‚  SDF/    â”‚ â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚  URDF    â”‚ â”‚
â”‚                                                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Implementation

### Step 1: Sensor Parameter Data Structures

```python
#!/usr/bin/env python3
"""
Real-to-Sim Parameter Estimation
Estimate simulation parameters from real-world sensor data
"""

import numpy as np
import json
from dataclasses import dataclass, field
from typing import Dict, List, Tuple, Optional, Callable
from scipy import optimize, stats
from scipy.spatial.transform import Rotation
from collections import defaultdict
import warnings


@dataclass
class SensorParameters:
    """Estimated sensor parameters for simulation configuration

    These parameters define how sensors behave in simulation
    to match real hardware characteristics.
    """
    # Camera intrinsic parameters
    focal_length: Tuple[float, float] = (500.0, 500.0)  # fx, fy in pixels
    principal_point: Tuple[float, float] = (320.0, 240.0)  # cx, cy in pixels
    distortion_coeffs: List[float] = field(
        default_factory=lambda: [0.0, 0.0, 0.0, 0.0, 0.0]  # k1, k2, p1, p2, k3
    )

    # IMU parameters - critical for state estimation
    accel_bias: Tuple[float, float, float] = (0.0, 0.0, 0.0)  # m/sÂ²
    accel_scale: Tuple[float, float, float] = (1.0, 1.0, 1.0)  # scale factors
    gyro_bias: Tuple[float, float, float] = (0.0, 0.0, 0.0)  # rad/s
    gyro_scale: Tuple[float, float, float] = (1.0, 1.0, 1.0)  # scale factors
    noise_density: Tuple[float, float, float] = (0.01, 0.01, 0.01)  # m/sÂ²/âˆšHz

    # Depth sensor parameters
    depth_scale: float = 0.001  # meters per unit (e.g., 0.001 for mm)
    depth_offset: float = 0.0  # systematic offset in meters
    min_depth: float = 0.1  # minimum valid depth
    max_depth: float = 10.0  # maximum valid depth


@dataclass
class PhysicsParameters:
    """Estimated physics parameters for rigid body simulation

    These parameters affect how objects move and interact
    in the physics engine.
    """
    mass: float = 1.0  # kg
    inertia: Tuple[float, ...] = (
        1.0, 0.0, 0.0,  # Ixx, Ixy, Ixz
        0.0, 1.0, 0.0,  # Iyx, Iyy, Iyz
        0.0, 0.0, 1.0   # Izx, Izy, Izz
    )  # kgÂ·mÂ² (3x3 inertia tensor as flat tuple)
    friction_coefficient: float = 0.5  # Coulomb friction Î¼
    restitution: float = 0.3  # Coefficient of restitution (bounciness)
    linear_damping: float = 0.5  # Linear velocity damping
    angular_damping: float = 0.5  # Angular velocity damping
```

---

### Step 2: Camera Parameter Estimation

```python
class CameraParameterEstimator:
    """Estimate camera intrinsic parameters from calibration data

    Uses checkerboard or ChArUco patterns to find correspondences
    between known 3D points and detected 2D image points.
    """

    def __init__(self, image_size: Tuple[int, int] = (640, 480)):
        """Initialize estimator

        Args:
            image_size: (width, height) of camera images
        """
        self.image_size = image_size
        self.detected_corners = []

    def detect_charuco_corners(
        self,
        images: List[np.ndarray],
        board_size: Tuple[int, int] = (5, 7),
        square_size: float = 0.03
    ) -> List[np.ndarray]:
        """Detect ChArUco board corners in calibration images

        ChArUco boards combine ArUco markers with checkerboards,
        providing robust detection even with partial occlusion.

        Args:
            images: List of BGR calibration images
            board_size: (columns, rows) of internal corners
            square_size: Size of squares in meters

        Returns:
            List of detected corner arrays
        """
        import cv2

        # Create ChArUco board definition
        dictionary = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_50)
        board = cv2.aruco.CharucoBoard(
            board_size, square_size, 0.8 * square_size, dictionary
        )

        all_corners = []

        for image in images:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

            # Detect ArUco markers first
            corners, ids, rejected = cv2.aruco.detectMarkers(gray, dictionary)

            if len(corners) > 0:
                # Interpolate ChArUco corners from ArUco detections
                charuco_corners, charuco_ids = cv2.aruco.interpolateCornersCharuco(
                    corners, ids, gray, board
                )

                # Need at least 6 corners for calibration
                if charuco_corners is not None and len(charuco_corners) > 6:
                    all_corners.append(charuco_corners.reshape(-1, 2))

        self.detected_corners = all_corners
        return all_corners

    def collect_corner_points(
        self,
        images: List[np.ndarray],
        pattern_size: Tuple[int, int] = (9, 6),
        square_size: float = 0.025
    ) -> Tuple[List[np.ndarray], List[np.ndarray]]:
        """Collect corner points from checkerboard images

        Standard checkerboard calibration - requires full board visibility.

        Args:
            images: List of BGR calibration images
            pattern_size: (columns, rows) of internal corners
            square_size: Size of squares in meters

        Returns:
            Tuple of (world_points_list, image_points_list)
        """
        import cv2

        world_points = []
        image_points = []

        # Generate 3D world coordinates (Z=0 plane)
        objp = np.zeros((pattern_size[1] * pattern_size[0], 3), np.float32)
        objp[:, :2] = np.mgrid[0:pattern_size[0], 0:pattern_size[1]].T.reshape(-1, 2)
        objp *= square_size

        for image in images:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

            # Find checkerboard corners
            success, corners = cv2.findChessboardCorners(
                gray, pattern_size,
                cv2.CALIB_CB_ADAPTIVE_THRESH + cv2.CALIB_CB_NORMALIZE_IMAGE
            )

            if success:
                # Refine corner locations to sub-pixel accuracy
                corners_refined = cv2.cornerSubPix(
                    gray, corners, (11, 11), (-1, -1),
                    criteria=(cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)
                )

                world_points.append(objp)
                image_points.append(corners_refined.reshape(-1, 2))

        return world_points, image_points

    def estimate_intrinsics(
        self,
        world_points: List[np.ndarray],
        image_points: List[np.ndarray]
    ) -> Tuple[np.ndarray, np.ndarray, float]:
        """Estimate camera intrinsic matrix and distortion coefficients

        Uses Zhang's method implemented in OpenCV.

        Args:
            world_points: List of 3D point arrays (one per image)
            image_points: List of 2D point arrays (one per image)

        Returns:
            Tuple of (camera_matrix, distortion_coeffs, reprojection_error)
        """
        import cv2

        # Initial camera matrix guess
        camera_matrix = np.array([
            [self.image_size[0], 0, self.image_size[0]/2],
            [0, self.image_size[0], self.image_size[1]/2],
            [0, 0, 1]
        ], dtype=np.float64)

        dist_coeffs = np.zeros(5)

        # Run calibration
        ret, camera_matrix, dist_coeffs, rvecs, tvecs = cv2.calibrateCamera(
            world_points,
            image_points,
            self.image_size,
            camera_matrix,
            dist_coeffs,
            flags=cv2.CALIB_USE_INTRINSIC_GUESS
        )

        return camera_matrix, dist_coeffs, ret  # ret is reprojection error

    def estimate_from_calibration_images(
        self,
        calibration_images: List[np.ndarray],
        min_images: int = 10
    ) -> SensorParameters:
        """Complete camera calibration from images

        Args:
            calibration_images: List of BGR calibration images
            min_images: Minimum number of valid images required

        Returns:
            SensorParameters with camera intrinsics filled

        Raises:
            ValueError: If insufficient valid calibration images
        """
        # Detect corners in all images
        world_points, image_points = self.collect_corner_points(calibration_images)

        if len(world_points) < min_images:
            raise ValueError(
                f"Need at least {min_images} valid images, got {len(world_points)}"
            )

        # Estimate intrinsics
        camera_matrix, dist_coeffs, reproj_error = self.estimate_intrinsics(
            world_points, image_points
        )

        print(f"Calibration complete. Reprojection error: {reproj_error:.3f} pixels")

        return SensorParameters(
            focal_length=(camera_matrix[0, 0], camera_matrix[1, 1]),
            principal_point=(camera_matrix[0, 2], camera_matrix[1, 2]),
            distortion_coeffs=dist_coeffs.flatten().tolist()
        )
```

:::tip Elite Insight âš¡
**Calibration Best Practices**:
1. **Image diversity**: Capture the board at various angles (Â±45Â°) and distances
2. **Cover the frame**: Ensure corners appear in all regions of the image
3. **Lighting consistency**: Avoid shadows on the calibration target
4. **Motion blur**: Use short exposure times to avoid blur
5. **Minimum images**: Use 20-30 images for reliable results

```python
def evaluate_calibration_coverage(image_points: List[np.ndarray],
                                   image_size: Tuple[int, int]) -> Dict:
    """Check if calibration images cover the full frame"""
    all_points = np.vstack(image_points)

    # Divide image into 3x3 grid
    w, h = image_size
    grid_coverage = np.zeros((3, 3))

    for x, y in all_points:
        gx = min(2, int(x / (w/3)))
        gy = min(2, int(y / (h/3)))
        grid_coverage[gy, gx] += 1

    return {
        'grid_coverage': grid_coverage,
        'min_points_per_region': grid_coverage.min(),
        'well_distributed': grid_coverage.min() > 10
    }
```
:::

---

### Step 3: IMU Parameter Estimation

```python
class IMUParameterEstimator:
    """Estimate IMU noise and bias parameters from stationary data

    IMU calibration requires the sensor to be completely stationary
    for accurate bias and noise characterization.
    """

    def __init__(self, sampling_rate: float = 100.0):
        """Initialize estimator

        Args:
            sampling_rate: IMU sampling frequency in Hz
        """
        self.sampling_rate = sampling_rate
        self.dt = 1.0 / sampling_rate

    def estimate_bias_instability(
        self,
        gyro_data: np.ndarray,
        tau_values: List[float] = None
    ) -> Dict[str, Dict]:
        """Estimate bias instability using Allan variance analysis

        Allan variance reveals different noise components at different
        averaging times (tau). The minimum of the Allan deviation curve
        corresponds to bias instability.

        Args:
            gyro_data: Nx3 array of gyroscope readings (rad/s)
            tau_values: List of averaging times to evaluate

        Returns:
            Dictionary with bias instability for each axis
        """
        if tau_values is None:
            # Logarithmically spaced tau values
            max_tau = len(gyro_data) // 10
            tau_values = np.logspace(0, np.log10(max_tau), 50).astype(int)
            tau_values = np.unique(tau_values)

        results = {}

        for axis in range(3):
            signal = gyro_data[:, axis]

            # Compute Allan variance at each tau
            allan_var = []
            valid_taus = []

            for tau in tau_values:
                n_samples = int(tau)
                if n_samples >= len(signal) // 2:
                    continue

                # Number of complete clusters
                n_clusters = len(signal) // n_samples

                if n_clusters < 2:
                    continue

                # Compute cluster averages
                truncated = signal[:n_clusters * n_samples]
                clusters = truncated.reshape(n_clusters, n_samples)
                cluster_means = np.mean(clusters, axis=1)

                # Allan variance: mean of squared differences of consecutive averages
                diffs = cluster_means[1:] - cluster_means[:-1]
                avar = np.mean(diffs ** 2) / 2

                allan_var.append(avar)
                valid_taus.append(tau * self.dt)  # Convert to seconds

            if len(allan_var) > 0:
                allan_var = np.array(allan_var)
                valid_taus = np.array(valid_taus)
                allan_dev = np.sqrt(allan_var)

                # Bias instability is minimum of Allan deviation
                min_idx = np.argmin(allan_dev)
                bias_instability = allan_dev[min_idx]

                axis_names = ['x', 'y', 'z']
                results[f'axis_{axis_names[axis]}'] = {
                    'bias_instability_rad_s': float(bias_instability),
                    'bias_instability_deg_h': float(bias_instability * 3600 * 180 / np.pi),
                    'tau_optimal_s': float(valid_taus[min_idx]),
                    'allan_deviation': allan_dev.tolist(),
                    'tau_values': valid_taus.tolist()
                }

        return results

    def estimate_noise_density(
        self,
        accel_data: np.ndarray,
        gyro_data: np.ndarray
    ) -> Dict[str, np.ndarray]:
        """Estimate noise density (white noise component)

        Noise density represents the power spectral density of
        the white noise, typically given in units/âˆšHz.

        Args:
            accel_data: Nx3 accelerometer readings (m/sÂ²)
            gyro_data: Nx3 gyroscope readings (rad/s)

        Returns:
            Dictionary with noise density estimates
        """
        # Standard deviation represents RMS noise
        accel_noise = np.std(accel_data, axis=0)
        gyro_noise = np.std(gyro_data, axis=0)

        # Convert to noise density (divide by âˆšbandwidth)
        sqrt_dt = np.sqrt(self.dt)

        return {
            'accel_noise_density': accel_noise * sqrt_dt,  # m/sÂ²/âˆšHz
            'gyro_noise_density': gyro_noise * sqrt_dt,    # rad/s/âˆšHz
            'accel_noise_std': accel_noise,
            'gyro_noise_std': gyro_noise,
        }

    def estimate_bias_from_stationary(
        self,
        accel_data: np.ndarray,
        gyro_data: np.ndarray,
        gravity: float = 9.81
    ) -> Dict[str, np.ndarray]:
        """Estimate sensor biases from stationary data

        When stationary:
        - Accelerometer should read [0, 0, g] (assuming z-up)
        - Gyroscope should read [0, 0, 0]

        Args:
            accel_data: Nx3 accelerometer readings
            gyro_data: Nx3 gyroscope readings
            gravity: Expected gravity magnitude

        Returns:
            Dictionary with bias estimates
        """
        # Gyro bias is simply the mean (should be zero when stationary)
        gyro_bias = np.mean(gyro_data, axis=0)

        # Accel bias requires knowing orientation
        # Assume z-axis points up (common for tabletop calibration)
        accel_mean = np.mean(accel_data, axis=0)

        # Expected: [0, 0, g] for z-up orientation
        accel_bias = accel_mean.copy()
        accel_bias[2] -= gravity  # Remove expected gravity

        return {
            'accel_bias': accel_bias,
            'gyro_bias': gyro_bias,
            'accel_mean': accel_mean,
            'measured_gravity': np.linalg.norm(accel_mean)
        }

    def estimate_scale_factor(
        self,
        accel_data: np.ndarray,
        expected_gravity: float = 9.81
    ) -> np.ndarray:
        """Estimate accelerometer scale factor errors

        Scale factor errors cause the measured magnitude to differ
        from expected gravity when stationary.

        Args:
            accel_data: Nx3 accelerometer readings
            expected_gravity: Known gravity value

        Returns:
            Scale factors for each axis
        """
        measured_magnitude = np.linalg.norm(accel_data, axis=1)

        # Filter out samples with significant motion
        stationary_mask = np.abs(measured_magnitude - expected_gravity) < 0.5

        if not np.any(stationary_mask):
            return np.array([1.0, 1.0, 1.0])

        avg_magnitude = np.mean(measured_magnitude[stationary_mask])
        scale_correction = expected_gravity / avg_magnitude

        # Apply uniform scale correction (simplified)
        return np.array([scale_correction, scale_correction, scale_correction])

    def estimate_all_parameters(
        self,
        accel_data: np.ndarray,
        gyro_data: np.ndarray,
        duration_seconds: float = 60.0
    ) -> SensorParameters:
        """Estimate all IMU parameters from stationary data

        Args:
            accel_data: Nx3 accelerometer readings
            gyro_data: Nx3 gyroscope readings
            duration_seconds: Duration for bias averaging

        Returns:
            SensorParameters with IMU values filled
        """
        # Use first portion for bias estimation
        bias_samples = int(min(duration_seconds * self.sampling_rate, len(accel_data) // 2))

        bias_est = self.estimate_bias_from_stationary(
            accel_data[:bias_samples],
            gyro_data[:bias_samples]
        )

        # Use remaining data for noise estimation
        noise_est = self.estimate_noise_density(
            accel_data[bias_samples:],
            gyro_data[bias_samples:]
        )

        scale_est = self.estimate_scale_factor(accel_data[bias_samples:])

        return SensorParameters(
            accel_bias=tuple(bias_est['accel_bias'].tolist()),
            accel_scale=tuple(scale_est.tolist()),
            gyro_bias=tuple(bias_est['gyro_bias'].tolist()),
            gyro_scale=(1.0, 1.0, 1.0),
            noise_density=tuple(noise_est['accel_noise_density'].tolist())
        )
```

---

### Step 4: Optimization-Based Parameter Fitting

```python
#!/usr/bin/env python3
"""
Optimization-Based Parameter Estimation
Use gradient-based and gradient-free optimization to fit simulation parameters
"""

from dataclasses import dataclass


@dataclass
class OptimizationConfig:
    """Configuration for parameter optimization"""
    method: str = 'Nelder-Mead'  # Gradient-free method
    max_iterations: int = 1000
    tolerance: float = 1e-8
    verbose: bool = True


class ParameterOptimizer:
    """Generic parameter optimization framework

    Fits simulation parameters by minimizing the difference
    between simulated and real sensor outputs.
    """

    def __init__(self, config: OptimizationConfig = None):
        self.config = config or OptimizationConfig()
        self.history = []  # Track optimization progress

    def create_objective_function(
        self,
        sim_func: Callable,
        real_data: np.ndarray,
        param_bounds: Dict[str, Tuple[float, float]]
    ) -> Tuple[Callable, List[Tuple[float, float]]]:
        """Create objective function for optimization

        Args:
            sim_func: Function that simulates sensor output given parameters
            real_data: Real sensor measurements to match
            param_bounds: Parameter names mapped to (min, max) bounds

        Returns:
            Tuple of (objective_function, bounds_list)
        """
        param_names = list(param_bounds.keys())
        bounds = [param_bounds[name] for name in param_names]

        def objective(params: np.ndarray) -> float:
            """Compute MSE between simulated and real data"""
            param_dict = {name: params[i] for i, name in enumerate(param_names)}

            try:
                sim_output = sim_func(**param_dict)
                error = np.mean((sim_output - real_data) ** 2)
            except Exception as e:
                error = float('inf')

            # Record history for analysis
            self.history.append({
                'params': param_dict.copy(),
                'error': error
            })

            return error

        return objective, bounds

    def optimize(
        self,
        objective_func: Callable,
        bounds: List[Tuple[float, float]],
        initial_params: np.ndarray
    ) -> Tuple[np.ndarray, float, Dict]:
        """Run optimization to find best parameters

        Args:
            objective_func: Function to minimize
            bounds: Parameter bounds
            initial_params: Starting parameter values

        Returns:
            Tuple of (best_params, best_error, metadata)
        """
        self.history = []  # Reset history

        result = optimize.minimize(
            objective_func,
            initial_params,
            method=self.config.method,
            bounds=bounds,
            options={
                'maxiter': self.config.max_iterations,
                'disp': self.config.verbose
            }
        )

        return result.x, result.fun, {
            'success': result.success,
            'iterations': result.nit,
            'message': str(result.message),
            'history_length': len(self.history)
        }

    def differential_evolution(
        self,
        objective_func: Callable,
        bounds: List[Tuple[float, float]],
        population_size: int = 15
    ) -> Tuple[np.ndarray, float, Dict]:
        """Global optimization using differential evolution

        More robust than local methods for multimodal problems.

        Args:
            objective_func: Function to minimize
            bounds: Parameter bounds
            population_size: Population multiplier

        Returns:
            Tuple of (best_params, best_error, metadata)
        """
        self.history = []

        result = optimize.differential_evolution(
            objective_func,
            bounds,
            maxiter=self.config.max_iterations,
            popsize=population_size,
            disp=self.config.verbose
        )

        return result.x, result.fun, {
            'success': result.success,
            'iterations': result.nit,
            'method': 'differential_evolution'
        }


def estimate_imu_parameters_optimization(
    true_trajectory: np.ndarray,
    measured_imu: np.ndarray,
    sampling_rate: float = 100.0
) -> Dict:
    """Estimate IMU parameters using trajectory optimization

    Finds parameters that minimize dead-reckoning error.

    Args:
        true_trajectory: Nx3 ground truth positions
        measured_imu: Nx3 IMU accelerometer readings
        sampling_rate: IMU sampling frequency

    Returns:
        Dictionary with estimated parameters
    """
    dt = 1.0 / sampling_rate

    def simulate_trajectory(params: np.ndarray) -> np.ndarray:
        """Integrate IMU to get trajectory with given bias/scale"""
        accel_bias = params[:3]
        accel_scale = params[6:9]

        # Correct measurements
        corrected = np.zeros_like(measured_imu)
        for i in range(3):
            corrected[:, i] = (measured_imu[:, i] - accel_bias[i]) * accel_scale[i]

        # Double integrate to get position
        velocity = np.cumsum(corrected * dt, axis=0)
        position = np.cumsum(velocity * dt, axis=0)

        return position

    # Initial guess: bias from first samples, scale = 1
    accel_mean = np.mean(measured_imu[:10], axis=0)
    accel_bias_init = accel_mean.copy()
    accel_bias_init[2] -= 9.81  # Remove gravity

    initial_params = np.array([
        *accel_bias_init,  # accel bias (3)
        0, 0, 0,           # gyro bias (3)
        1, 1, 1,           # accel scale (3)
        0.01               # noise std (1)
    ])

    def error_func(params):
        sim_position = simulate_trajectory(params)
        # Match trajectory length
        min_len = min(len(sim_position), len(true_trajectory))
        return np.mean((sim_position[:min_len] - true_trajectory[:min_len]) ** 2)

    # Optimize
    result = optimize.minimize(
        error_func,
        initial_params,
        method='Nelder-Mead',
        options={'maxiter': 500, 'disp': True}
    )

    return {
        'accel_bias': result.x[:3].tolist(),
        'gyro_bias': result.x[3:6].tolist(),
        'accel_scale': result.x[6:9].tolist(),
        'noise_std': result.x[9] if len(result.x) > 9 else 0.01,
        'optimization_success': result.success,
        'final_error': float(result.fun),
        'iterations': result.nit
    }
```

---

### Step 5: Uncertainty Quantification

```python
class ParameterUncertaintyEstimator:
    """Estimate uncertainty in estimated parameters

    Uncertainty quantification is critical for knowing how much
    to trust the estimated parameters.
    """

    def __init__(self, confidence: float = 0.95):
        """Initialize estimator

        Args:
            confidence: Confidence level for intervals (e.g., 0.95 for 95%)
        """
        self.confidence = confidence

    def bootstrap_parameter_estimation(
        self,
        data: np.ndarray,
        estimator_func: Callable,
        n_bootstrap: int = 100
    ) -> Dict:
        """Bootstrap resampling for uncertainty estimation

        Repeatedly resamples the data and re-estimates parameters
        to get a distribution of parameter estimates.

        Args:
            data: Original data array
            estimator_func: Function that estimates params from data
            n_bootstrap: Number of bootstrap iterations

        Returns:
            Dictionary with mean, std, and confidence intervals
        """
        n_samples = len(data)
        param_samples = []

        for i in range(n_bootstrap):
            # Resample with replacement
            indices = np.random.choice(n_samples, n_samples, replace=True)
            resampled_data = data[indices]

            try:
                params = estimator_func(resampled_data)
                param_samples.append(params)
            except Exception:
                continue

            if (i + 1) % 20 == 0:
                print(f"  Bootstrap {i+1}/{n_bootstrap}")

        if len(param_samples) == 0:
            return {'error': 'All bootstrap iterations failed'}

        param_array = np.array(param_samples)

        # Compute statistics
        means = np.mean(param_array, axis=0)
        stds = np.std(param_array, axis=0)

        # Percentile-based confidence intervals
        alpha = (1 - self.confidence) / 2
        lower = np.percentile(param_array, alpha * 100, axis=0)
        upper = np.percentile(param_array, (1 - alpha) * 100, axis=0)

        return {
            'means': means.tolist(),
            'stds': stds.tolist(),
            'n_successful': len(param_samples),
            'confidence_level': self.confidence,
            'confidence_intervals': {
                'lower': lower.tolist(),
                'upper': upper.tolist(),
            }
        }

    def cross_validate_parameters(
        self,
        full_data: np.ndarray,
        estimator_func: Callable,
        evaluator_func: Callable,
        n_folds: int = 5
    ) -> Dict:
        """K-fold cross-validation for parameter estimation

        Estimates parameters on training folds and evaluates
        on held-out test folds.

        Args:
            full_data: Complete dataset
            estimator_func: Function to estimate parameters
            evaluator_func: Function to evaluate parameters
            n_folds: Number of cross-validation folds

        Returns:
            Dictionary with fold errors and statistics
        """
        n_samples = len(full_data)
        fold_size = n_samples // n_folds
        indices = np.arange(n_samples)
        np.random.shuffle(indices)

        fold_errors = []
        fold_params = []

        for fold in range(n_folds):
            # Split into train/test
            test_start = fold * fold_size
            test_end = test_start + fold_size
            test_idx = indices[test_start:test_end]
            train_idx = np.concatenate([indices[:test_start], indices[test_end:]])

            train_data = full_data[train_idx]
            test_data = full_data[test_idx]

            try:
                params = estimator_func(train_data)
                error = evaluator_func(test_data, params)
                fold_errors.append(error)
                fold_params.append(params)
            except Exception as e:
                fold_errors.append(float('inf'))
                print(f"Fold {fold} failed: {e}")

        valid_errors = [e for e in fold_errors if e != float('inf')]

        return {
            'fold_errors': fold_errors,
            'mean_error': np.mean(valid_errors) if valid_errors else float('inf'),
            'std_error': np.std(valid_errors) if valid_errors else 0,
            'n_successful_folds': len(valid_errors),
            'cv_score': np.mean(valid_errors) / (np.std(valid_errors) + 1e-6) if valid_errors else float('inf')
        }


class ParameterValidator:
    """Validate estimated parameters against ground truth or physical constraints"""

    def __init__(self, tolerance: float = 0.1):
        self.tolerance = tolerance

    def validate_camera_params(
        self,
        estimated: Dict,
        ground_truth: Dict
    ) -> Dict:
        """Validate camera calibration against ground truth"""
        results = {}

        # Focal length validation
        est_fx = estimated['camera_matrix'][0][0]
        est_fy = estimated['camera_matrix'][1][1]
        gt_fx = ground_truth['camera_matrix'][0][0]
        gt_fy = ground_truth['camera_matrix'][1][1]

        fx_error = abs(est_fx - gt_fx) / gt_fx
        fy_error = abs(est_fy - gt_fy) / gt_fy

        results['focal_length'] = {
            'estimated': (est_fx, est_fy),
            'ground_truth': (gt_fx, gt_fy),
            'relative_error': (fx_error, fy_error),
            'passed': fx_error < self.tolerance and fy_error < self.tolerance
        }

        # Principal point validation
        est_cx = estimated['camera_matrix'][0][2]
        est_cy = estimated['camera_matrix'][1][2]
        gt_cx = ground_truth['camera_matrix'][0][2]
        gt_cy = ground_truth['camera_matrix'][1][2]

        results['principal_point'] = {
            'estimated': (est_cx, est_cy),
            'ground_truth': (gt_cx, gt_cy),
            'error_pixels': (abs(est_cx - gt_cx), abs(est_cy - gt_cy)),
            'passed': abs(est_cx - gt_cx) < 10 and abs(est_cy - gt_cy) < 10
        }

        return results

    def validate_imu_params(
        self,
        estimated: Dict,
        ground_truth: Dict
    ) -> Dict:
        """Validate IMU calibration against ground truth"""
        results = {}

        # Accelerometer bias
        est_bias = np.array(estimated['accel_bias'])
        gt_bias = np.array(ground_truth['accel_bias'])
        bias_error = np.linalg.norm(est_bias - gt_bias)

        results['accel_bias'] = {
            'estimated': est_bias.tolist(),
            'ground_truth': gt_bias.tolist(),
            'error_magnitude': float(bias_error),
            'passed': bias_error < 0.1  # 0.1 m/sÂ²
        }

        # Gyroscope bias
        est_gyro = np.array(estimated['gyro_bias'])
        gt_gyro = np.array(ground_truth['gyro_bias'])
        gyro_error = np.linalg.norm(est_gyro - gt_gyro)

        results['gyro_bias'] = {
            'estimated': est_gyro.tolist(),
            'ground_truth': gt_gyro.tolist(),
            'error_magnitude': float(gyro_error),
            'passed': gyro_error < 0.01  # 0.01 rad/s
        }

        return results
```

---

### Step 6: End-to-End Pipeline

```python
#!/usr/bin/env python3
"""
End-to-End Parameter Estimation Pipeline
Complete workflow from data collection to simulation config
"""

from pathlib import Path


@dataclass
class EstimationResult:
    """Complete result of parameter estimation"""
    parameters: Dict
    uncertainty: Dict
    validation_results: Dict
    metadata: Dict


class ParameterEstimationPipeline:
    """Complete pipeline for real-to-sim parameter estimation

    Orchestrates:
    1. Data loading and preprocessing
    2. Parameter estimation for each sensor type
    3. Uncertainty quantification
    4. Validation and export
    """

    def __init__(self, output_dir: str = "/tmp/parameter_estimation"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.camera_estimator = None
        self.imu_estimator = None

    def estimate_camera_parameters(
        self,
        calibration_images: List[np.ndarray],
        image_size: Tuple[int, int],
        ground_truth: Optional[Dict] = None
    ) -> EstimationResult:
        """Estimate camera parameters from calibration images"""
        print("=" * 50)
        print("CAMERA PARAMETER ESTIMATION")
        print("=" * 50)

        self.camera_estimator = CameraParameterEstimator(image_size)

        try:
            params = self.camera_estimator.estimate_from_calibration_images(
                calibration_images
            )
            success = True
        except ValueError as e:
            print(f"Calibration failed: {e}")
            params = SensorParameters()
            success = False

        # Build parameter dictionary
        param_dict = {
            'focal_length': params.focal_length,
            'principal_point': params.principal_point,
            'distortion_coeffs': params.distortion_coeffs,
            'camera_matrix': [
                [params.focal_length[0], 0, params.principal_point[0]],
                [0, params.focal_length[1], params.principal_point[1]],
                [0, 0, 1]
            ]
        }

        # Validation if ground truth provided
        validation_results = {}
        if ground_truth and success:
            validator = ParameterValidator()
            validation_results = validator.validate_camera_params(
                param_dict, ground_truth
            )

        return EstimationResult(
            parameters=param_dict,
            uncertainty={'method': 'reprojection_error'},
            validation_results=validation_results,
            metadata={
                'type': 'camera',
                'n_images': len(calibration_images),
                'success': success
            }
        )

    def estimate_imu_parameters(
        self,
        accel_data: np.ndarray,
        gyro_data: np.ndarray,
        sampling_rate: float = 100.0,
        ground_truth: Optional[Dict] = None
    ) -> EstimationResult:
        """Estimate IMU parameters from stationary data"""
        print("=" * 50)
        print("IMU PARAMETER ESTIMATION")
        print("=" * 50)

        self.imu_estimator = IMUParameterEstimator(sampling_rate)

        # Basic parameter estimation
        params = self.imu_estimator.estimate_all_parameters(
            accel_data, gyro_data
        )

        # Allan variance analysis
        print("Running Allan variance analysis...")
        bias_instability = self.imu_estimator.estimate_bias_instability(gyro_data)
        noise_density = self.imu_estimator.estimate_noise_density(accel_data, gyro_data)

        param_dict = {
            'accel_bias': params.accel_bias,
            'accel_scale': params.accel_scale,
            'gyro_bias': params.gyro_bias,
            'gyro_scale': params.gyro_scale,
            'noise_density': params.noise_density,
        }

        uncertainty = {
            'bias_instability': bias_instability,
            'noise_density': noise_density,
            'method': 'allan_variance'
        }

        # Validation
        validation_results = {}
        if ground_truth:
            validator = ParameterValidator()
            validation_results = validator.validate_imu_params(
                param_dict, ground_truth
            )

        return EstimationResult(
            parameters=param_dict,
            uncertainty=uncertainty,
            validation_results=validation_results,
            metadata={
                'type': 'imu',
                'sampling_rate': sampling_rate,
                'n_samples': len(accel_data)
            }
        )

    def export_gazebo_config(
        self,
        camera_result: EstimationResult,
        imu_result: EstimationResult,
        output_file: str = "sensor_config.sdf"
    ) -> Path:
        """Export estimated parameters as Gazebo SDF configuration"""
        output_path = self.output_dir / output_file

        sdf_content = f'''<?xml version="1.0"?>
<sdf version="1.9">
  <!-- Auto-generated from real-to-sim parameter estimation -->

  <!-- Camera Configuration -->
  <sensor name="calibrated_camera" type="camera">
    <camera>
      <horizontal_fov>{2 * np.arctan(camera_result.parameters['focal_length'][0] / 320):.6f}</horizontal_fov>
      <image>
        <width>640</width>
        <height>480</height>
      </image>
      <distortion>
        <k1>{camera_result.parameters['distortion_coeffs'][0]:.6f}</k1>
        <k2>{camera_result.parameters['distortion_coeffs'][1]:.6f}</k2>
        <p1>{camera_result.parameters['distortion_coeffs'][2]:.6f}</p1>
        <p2>{camera_result.parameters['distortion_coeffs'][3]:.6f}</p2>
        <k3>{camera_result.parameters['distortion_coeffs'][4] if len(camera_result.parameters['distortion_coeffs']) > 4 else 0:.6f}</k3>
      </distortion>
    </camera>
  </sensor>

  <!-- IMU Configuration -->
  <sensor name="calibrated_imu" type="imu">
    <imu>
      <angular_velocity>
        <x>
          <noise type="gaussian">
            <mean>{imu_result.parameters['gyro_bias'][0]:.8f}</mean>
            <stddev>{imu_result.parameters['noise_density'][0]:.8f}</stddev>
          </noise>
        </x>
        <y>
          <noise type="gaussian">
            <mean>{imu_result.parameters['gyro_bias'][1]:.8f}</mean>
            <stddev>{imu_result.parameters['noise_density'][1]:.8f}</stddev>
          </noise>
        </y>
        <z>
          <noise type="gaussian">
            <mean>{imu_result.parameters['gyro_bias'][2]:.8f}</mean>
            <stddev>{imu_result.parameters['noise_density'][2]:.8f}</stddev>
          </noise>
        </z>
      </angular_velocity>
      <linear_acceleration>
        <x>
          <noise type="gaussian">
            <mean>{imu_result.parameters['accel_bias'][0]:.8f}</mean>
            <stddev>{imu_result.parameters['noise_density'][0]:.8f}</stddev>
          </noise>
        </x>
        <y>
          <noise type="gaussian">
            <mean>{imu_result.parameters['accel_bias'][1]:.8f}</mean>
            <stddev>{imu_result.parameters['noise_density'][1]:.8f}</stddev>
          </noise>
        </y>
        <z>
          <noise type="gaussian">
            <mean>{imu_result.parameters['accel_bias'][2]:.8f}</mean>
            <stddev>{imu_result.parameters['noise_density'][2]:.8f}</stddev>
          </noise>
        </z>
      </linear_acceleration>
    </imu>
  </sensor>
</sdf>
'''

        with open(output_path, 'w') as f:
            f.write(sdf_content)

        print(f"Exported Gazebo config to {output_path}")
        return output_path

    def export_json(
        self,
        result: EstimationResult,
        filename: str
    ) -> Path:
        """Export parameters to JSON file"""
        output_file = self.output_dir / filename

        # Convert numpy types to Python natives
        def convert(obj):
            if isinstance(obj, np.ndarray):
                return obj.tolist()
            if isinstance(obj, (np.float32, np.float64)):
                return float(obj)
            if isinstance(obj, (np.int32, np.int64)):
                return int(obj)
            return obj

        export_data = {
            'parameters': result.parameters,
            'uncertainty': result.uncertainty,
            'validation': result.validation_results,
            'metadata': result.metadata,
        }

        with open(output_file, 'w') as f:
            json.dump(export_data, f, indent=2, default=convert)

        print(f"Exported JSON to {output_file}")
        return output_file
```

---

## Industry Spotlights

:::info Industry Spotlight: Tesla Autopilot
**How Tesla calibrates sensors for simulation:**

Tesla's simulation team uses extensive real-world driving data to calibrate their virtual cameras, radar, and ultrasonic sensors. Each vehicle's factory calibration is refined using on-road data, and these parameters feed directly into their simulation environment for algorithm validation.

**Key metrics they care about:**
- **Camera reprojection error**: < 0.5 pixels
- **IMU bias stability**: < 0.01Â°/h for gyro
- **Cross-sensor alignment**: < 1cm extrinsic error

**Lessons learned:**
"Calibration isn't a one-time event. Sensor parameters drift over time due to temperature, vibration, and aging. Continuous recalibration from operational data is essential."
:::

:::info Industry Spotlight: Boston Dynamics
**How Boston Dynamics calibrates robot sensors:**

Boston Dynamics uses automated calibration rigs that exercise each robot through known motions while recording all sensor data. Their parameter estimation pipelines run overnight, producing per-robot calibration files that are loaded at boot.

**Key metrics they care about:**
- **Joint encoder accuracy**: < 0.1Â° error
- **IMU Allan variance**: Characterized for each unit
- **Stereo baseline**: < 0.1mm error

**Lessons learned:**
"Every robot is different. Population statistics are useful, but per-unit calibration is essential for high-performance locomotion."
:::

---

## Agentic AI Integration

:::warning Agentic AI Integration ðŸ¤–
**For autonomous systems that self-calibrate:**

**Self-Calibration**: Agents can detect when calibration has drifted and trigger recalibration:
- Monitor reprojection errors during operation
- Detect IMU bias drift from navigation residuals
- Request recalibration when thresholds exceeded

**Online Parameter Estimation**:
```python
class SelfCalibratingAgent:
    """Agent that monitors and updates its own calibration"""

    def __init__(self, initial_params: SensorParameters):
        self.params = initial_params
        self.calibration_history = []
        self.drift_threshold = 0.1

    def check_calibration_health(self, recent_data: Dict) -> bool:
        """Monitor calibration quality from operational data"""
        # Check IMU consistency
        accel_magnitude = np.linalg.norm(recent_data['accel_mean'])
        expected_gravity = 9.81
        gravity_error = abs(accel_magnitude - expected_gravity)

        if gravity_error > self.drift_threshold:
            print(f"IMU calibration drift detected: {gravity_error:.3f} m/sÂ²")
            return False

        return True

    def request_recalibration(self) -> str:
        """Agent requests human-supervised recalibration"""
        return "CALIBRATION_NEEDED: IMU parameters have drifted beyond threshold"
```

**LLM/Agent Interface Pattern:**
```python
# Agent interprets calibration results
def agent_analyze_calibration(
    calibration_result: EstimationResult
) -> str:
    """LLM agent summarizes calibration quality"""

    prompt = f"""
    Calibration completed with these results:
    - Camera reprojection error: {calibration_result.metadata.get('reproj_error', 'N/A')}
    - IMU bias: {calibration_result.parameters.get('accel_bias', 'N/A')}
    - Validation passed: {calibration_result.validation_results}

    Summarize the calibration quality and recommend next steps.
    """
    return llm.generate(prompt)
```

**Safety Constraints:**
- Never auto-deploy calibration changes to safety-critical systems
- Require human approval for calibration updates
- Log all calibration changes with timestamps and data sources
:::

---

## Practice Exercises

### Exercise 1: Foundation (Beginner) ðŸŒ±
**Objective:** Collect stationary IMU data and compute basic bias
**Time:** ~20 minutes
**Skills Practiced:** Data collection, basic statistics

**Instructions:**
1. Place IMU sensor flat on a table (z-up orientation)
2. Record 60 seconds of accelerometer and gyroscope data
3. Compute the mean of each axis
4. Verify accelerometer z-axis reads approximately 9.81 m/sÂ²

**Success Criteria:**
- [ ] Collected 6000+ samples at 100 Hz
- [ ] Gyroscope means are close to zero (< 0.01 rad/s)
- [ ] Accelerometer z-mean is within 0.5 m/sÂ² of 9.81

<details>
<summary>ðŸ’¡ Hint</summary>
The gyroscope should read nearly zero on all axes when stationary. Any non-zero mean is the bias. The accelerometer measures gravity, so z-axis should be ~9.81 m/sÂ² for z-up orientation.
</details>

<details>
<summary>âœ… Solution</summary>

```python
import numpy as np

# Simulated stationary IMU data (replace with real data)
sampling_rate = 100  # Hz
duration = 60  # seconds
n_samples = int(sampling_rate * duration)

# Simulate with small bias and noise
true_accel_bias = np.array([0.02, -0.01, 0.05])
true_gyro_bias = np.array([0.001, -0.002, 0.0005])

accel_data = np.random.randn(n_samples, 3) * 0.01 + true_accel_bias
accel_data[:, 2] += 9.81  # Add gravity

gyro_data = np.random.randn(n_samples, 3) * 0.001 + true_gyro_bias

# Compute bias estimates
accel_mean = np.mean(accel_data, axis=0)
gyro_mean = np.mean(gyro_data, axis=0)

print(f"Accelerometer mean: {accel_mean}")
print(f"Gyroscope mean: {gyro_mean}")
print(f"Measured gravity: {accel_mean[2]:.3f} m/sÂ²")

# Bias = mean - expected
accel_bias_est = accel_mean.copy()
accel_bias_est[2] -= 9.81
print(f"Estimated accel bias: {accel_bias_est}")
print(f"Estimated gyro bias: {gyro_mean}")
```
</details>

---

### Exercise 2: Camera Calibration (Intermediate) ðŸ”§
**Objective:** Calibrate camera intrinsics from checkerboard images
**Time:** ~45 minutes
**Skills Practiced:** Image processing, optimization

**Instructions:**
1. Print a 9x6 checkerboard pattern (25mm squares)
2. Capture 20+ images from various angles and distances
3. Run the `CameraParameterEstimator` on your images
4. Verify reprojection error is below 0.5 pixels

**Success Criteria:**
- [ ] At least 15 valid calibration images
- [ ] Reprojection error < 0.5 pixels
- [ ] Focal length within expected range for your camera

---

### Exercise 3: Production Challenge (Advanced) âš¡
**Objective:** Build automated calibration pipeline with uncertainty
**Time:** ~90 minutes
**Skills Practiced:** Pipeline design, uncertainty quantification

**Scenario:** Your robotics company needs an automated calibration system that:
- Runs overnight with minimal supervision
- Produces confidence intervals on all parameters
- Detects calibration failures automatically
- Exports directly to simulation configs

**Requirements:**
1. Implement bootstrap uncertainty estimation for camera params
2. Add cross-validation for IMU parameters
3. Generate validation report comparing to ground truth
4. Export to both JSON and Gazebo SDF formats

---

### Exercise 4: Architect's Design (Expert) ðŸ—ï¸
**Objective:** Design fleet-wide calibration infrastructure
**Time:** ~2+ hours

**Design a system that:**
1. Collects calibration data from 100+ deployed robots
2. Detects per-robot calibration drift over time
3. Triggers automated recalibration when thresholds exceeded
4. Maintains calibration database with version history
5. Integrates with CI/CD for simulation updates

**Deliverable:** Architecture diagram + API specification

---

## Troubleshooting Guide

### Quick Fixes

| Symptom | Likely Cause | Quick Fix |
|---------|--------------|-----------|
| No corners detected | Poor lighting/focus | Improve lighting, check focus |
| High reprojection error | Board moving during capture | Use rigid board mount |
| IMU bias too large | Sensor not stationary | Ensure no vibration/motion |
| Allan variance fails | Insufficient data | Collect longer (>5 min) |
| Optimization diverges | Bad initial guess | Use grid search first |

### Diagnostic Decision Tree

```
Camera calibration failing?
â”œâ”€â”€ No corners detected
â”‚   â”œâ”€â”€ Check lighting â†’ Ensure even, bright lighting
â”‚   â””â”€â”€ Check focus â†’ Manual focus on calibration distance
â”œâ”€â”€ Corners detected but high error
â”‚   â”œâ”€â”€ Check board flatness â†’ Use rigid, flat board
â”‚   â””â”€â”€ Check image diversity â†’ Cover full frame
â””â”€â”€ Optimization fails
    â””â”€â”€ Check board dimensions â†’ Verify pattern_size matches

IMU calibration failing?
â”œâ”€â”€ Bias estimates unreasonable
â”‚   â”œâ”€â”€ Check orientation â†’ Ensure correct z-up assumption
â”‚   â””â”€â”€ Check motion â†’ Sensor must be completely stationary
â””â”€â”€ High noise estimates
    â””â”€â”€ Check sampling rate â†’ Verify actual vs expected rate
```

### Deep Dive: High Reprojection Error

**Symptoms:**
- Reprojection error > 1.0 pixels
- Calibration "succeeds" but results are poor
- Undistorted images look wrong

**Root Causes:**
1. **Rolling shutter** - Probability: High for consumer cameras
2. **Board deformation** - Probability: Medium
3. **Motion blur** - Probability: Medium

**Diagnosis Steps:**
```bash
# Check individual image errors
python -c "
import cv2
# Load calibration results
# Print per-image reprojection errors
"
```

**Solutions:**
- **Rolling shutter**: Use global shutter camera or keep board stationary
- **Board deformation**: Mount board on rigid aluminum plate
- **Motion blur**: Use faster shutter speed, tripod

---

## Summary

### Key Commands

| Task | Command/Code |
|------|-------------|
| Estimate camera params | `estimator.estimate_from_calibration_images(images)` |
| Estimate IMU params | `estimator.estimate_all_parameters(accel, gyro)` |
| Allan variance | `estimator.estimate_bias_instability(gyro_data)` |
| Bootstrap uncertainty | `uncertainty.bootstrap_parameter_estimation(data, func)` |
| Export to Gazebo | `pipeline.export_gazebo_config(camera, imu)` |

### Key Concepts Recap

| Concept | Key Insight |
|---------|-------------|
| **Real-to-Sim** | Infer simulation params from real sensor data |
| **Intrinsic Calibration** | Camera focal length, principal point, distortion |
| **Allan Variance** | Standard method for IMU noise characterization |
| **Bootstrap** | Resampling for parameter confidence intervals |
| **Validation** | Compare estimated vs ground truth params |

---

## What's Next?

Now that you can estimate simulation parameters from real data, the next sections cover using these parameters effectively:

- **M2-C3-S2**: Domain Adaptation Techniques - Handling remaining sim-to-real gaps
- **M2-C3-S3**: Uncertainty Quantification - Knowing when to trust predictions
- **M2-C3-S4**: Transfer Learning Strategies - Fine-tuning on real data

---

**Assessment Preparation**: Be ready to explain the difference between intrinsic and extrinsic calibration, interpret Allan variance plots, and design a complete parameter estimation pipeline with uncertainty quantification.
