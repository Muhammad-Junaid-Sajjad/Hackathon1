---
id: m2-c1-s3
title: World Files and Environmental Design
sidebar_position: 3
keywords: ['world-files', 'environment', 'sdf', 'lighting', 'objects', 'spawning']
---

# World Files and Environmental Design

## Overview

**World files** define the simulation environmentâ€”terrain, lighting, objects, atmospheric conditions, and scene composition. In Gazebo Ionic, worlds are described using **SDF (Simulation Description Format)**, an XML-based scene graph that specifies models, their poses, physics properties, and plugins. Effective world design is critical for sim-to-real transfer: realistic lighting ensures camera algorithms generalize, diverse object arrangements test manipulation robustness, and randomized environments reduce overfitting.

**What You'll Build**: A complete library of simulation worlds (indoor lab, warehouse, outdoor terrain), dynamic object spawning systems, lighting configurations for different times of day, and world plugins for environmental effects (wind, temperature gradients).

## Prerequisites

Before starting this section, ensure you have:

- **Completed [M2-C1-S1](./S1.md)**: Gazebo Ionic installed and verified
- **Completed [M2-C1-S2](./S2.md)**: Understanding of physics engine configuration
- **Basic XML/SDF knowledge**: Comfortable reading and editing XML files
- **ROS 2 Kilted Kaiju workspace**: Sourced and functional
- **Python 3.10+**: For running spawning and lighting scripts

**Hardware Requirements**:
- NVIDIA GPU recommended for real-time rendering
- 50GB free disk space for world assets
- 16GB RAM for complex scenes

## Learning Objectives

By the end of this section, you will be able to:

- **[Beginner]** Explain SDF world file structure and create a minimal simulation environment
- **[Beginner]** Add lighting sources and configure basic scene parameters
- **[Intermediate]** Design modular world components (walls, furniture, objects) for reuse
- **[Intermediate]** Implement dynamic object spawning during simulation runtime
- **[Advanced]** Configure domain randomization for lighting, textures, and object poses
- **[Advanced]** Optimize world performance for large-scale multi-robot simulation
- **[Expert]** Design procedural world generation pipelines for RL training at scale

## Key Concepts

| Term | Definition | Why It Matters |
|------|------------|----------------|
| **SDF (Simulation Description Format)** | XML-based format for describing robots and worlds | Standard for Gazebo world definition |
| **Static Model** | Model that doesn't participate in physics (fixed position) | Reduces computational load |
| **Directional Light** | Light simulating sun (parallel rays, shadows) | Primary illumination source |
| **Point Light** | Light radiating from a single point (ceiling lamps) | Indoor ambient lighting |
| **Spot Light** | Focused cone of light (task lighting) | Highlights specific areas |
| **Domain Randomization** | Varying simulation parameters during training | Improves sim-to-real transfer |
| **LOD (Level of Detail)** | Simplified geometry for distant objects | Performance optimization |

:::danger Latency Trap Warning
**Simulation environments must run locally, not over network.** Streaming world state from a remote server introduces unacceptable delays for control loops. For real-time robotics:
- Run Gazebo/Isaac Sim on the same machine as ROS 2 controllers
- Use GPU rendering locally (not remote X11 forwarding for physics)
- Only use cloud simulation for offline training batches
:::

## Skill-Level Pathways

:::note For Beginners
If you're new to world design, focus on:
1. Understanding the **Basic World File Structure** in Step 1
2. Creating a simple world with ground plane and one light
3. Adding static objects (tables, walls)
4. Completing **Exercise 1** to verify your setup

**Skip on first read**: Domain randomization, world plugins, procedural generation
:::

:::tip Intermediate Path
If you have ROS 2 experience and want production-ready environments:
1. Master the **Lighting Configuration** in Step 2
2. Implement **Dynamic Object Spawning** in Step 3
3. Create modular environment templates
4. Complete **Exercises 1-2**
:::

:::caution Advanced Path
For production systems and large-scale simulation:
1. Master domain randomization parameters
2. Optimize world performance for 10+ robots
3. Design procedural generation pipelines
4. Complete **Exercise 3** and attempt the **Architect Challenge**
:::

---

## Industry Perspectives

:::info Industry Spotlight: Amazon Robotics (Kiva)
**How Amazon Robotics uses world design:**
Amazon's fulfillment center simulations include 1000+ SKU variations, realistic warehouse lighting (high-bay LEDs with shadows), and accurate floor markings for robot localization. They use procedural generation to create millions of unique warehouse configurations.

**Key metrics they care about:**
- **Scene diversity**: 10,000+ unique object arrangements for training
- **Rendering fidelity**: PBR materials matching real warehouse surfaces
- **Generation speed**: 100+ worlds per minute for RL training

**Lessons learned:**
Lighting consistency between simulation and reality causes more sim-to-real failures than geometry differences. Invest heavily in lighting calibration.
:::

:::info Industry Spotlight: Waymo Self-Driving
**How Waymo uses world design:**
Waymo's simulation recreates entire cities with millions of objectsâ€”buildings, vehicles, pedestrians, traffic signals. They use photorealistic rendering with ray-tracing for camera sensor validation.

**Key metrics they care about:**
- **Geographic coverage**: 20+ million miles of road simulated
- **Weather variation**: Rain, snow, fog, glare conditions
- **Pedestrian behavior**: Realistic jaywalking, groups, strollers

**Lessons learned:**
The "long tail" of rare scenarios (unusual lighting, odd object configurations) is where most real-world failures occur. Prioritize world diversity over average-case realism.
:::

:::info Industry Spotlight: Boston Dynamics
**How Boston Dynamics uses world design:**
Spot and Atlas robots train in procedurally generated terrainâ€”stairs, rubble, slopes, narrow passages. They randomize surface friction, step heights, and gap widths to build robust locomotion policies.

**Key metrics they care about:**
- **Terrain difficulty**: 10 levels from flat to extreme
- **Surface variation**: Friction 0.2-1.5, compliance 0.1-10
- **Gap/step randomization**: Â±20% of nominal values

**Lessons learned:**
For locomotion, geometric variation matters more than visual realism. Train on ugly procedural terrain, deploy on real surfaces.
:::

---

## Hardware Requirements

**Workstation** (from M1-C1-S1)
- Ubuntu 24.04 LTS
- NVIDIA RTX 5080/6080 (16GB+ VRAM) for 2025-standard real-time PBR rendering
- ROS 2 Kilted Kaiju + Gazebo Harmonic (M2-C1-S1)
- 100GB free disk space for high-fidelity 2025 world assets

## Connection to Capstone

The capstone uses world design for:

1. **Training Environments**: Kitchen, warehouse, officeâ€”each with objects, furniture, lighting variations
2. **Sim-to-Real Transfer**: Domain randomization (lighting, textures, object poses) reduces reality gap
3. **Testing Scenarios**: Cluttered vs. clean environments, narrow corridors, stairs for locomotion
4. **Dataset Generation**: Spawn 1000+ object configurations, record RGB-D images with ground truth
5. **Multi-Robot Coordination**: Large worlds with multiple humanoids, obstacles, dynamic agents

**World Design Principles**:
- **Modularity**: Reusable world components (walls, tables, lighting presets)
- **Scalability**: Spawn/despawn objects dynamically during runtime
- **Realism**: PBR materials, accurate shadows, realistic clutter

## Implementation

### Step 1: Basic World File Structure

**World File**: `~/ros2_ws/src/humanoid_description/worlds/indoor_lab.world`

```xml
<?xml version="1.0"?>
<sdf version="1.9">
  <world name="indoor_lab">

    <!-- Physics (from M2-C1-S2) -->
    <physics name="default_physics" type="ode">
      <max_step_size>0.001</max_step_size>
      <real_time_factor>1.0</real_time_factor>
      <real_time_update_rate>1000.0</real_time_update_rate>
    </physics>

    <!-- Scene settings -->
    <scene>
      <ambient>0.4 0.4 0.4 1</ambient>  <!-- Ambient light (RGBA) -->
      <background>0.7 0.7 0.7 1</background>  <!-- Sky color -->
      <shadows>true</shadows>
      <grid>false</grid>  <!-- Hide grid lines -->
    </scene>

    <!-- Gravity -->
    <gravity>0 0 -9.81</gravity>

    <!-- Magnetic field (for IMU) -->
    <magnetic_field>5.5645e-6 22.8758e-6 -42.3884e-6</magnetic_field>

    <!-- Atmospheric model -->
    <atmosphere type="adiabatic">
      <temperature>298.15</temperature>  <!-- 25Â°C -->
      <pressure>101325</pressure>  <!-- Pa -->
      <temperature_gradient>-0.0065</temperature_gradient>
    </atmosphere>

    <!-- GUI settings -->
    <gui fullscreen="false">
      <camera name="user_camera">
        <pose>-5 -5 3 0 0.3 0.785</pose>
        <view_controller>orbit</view_controller>
        <projection_type>perspective</projection_type>
      </camera>
    </gui>

    <!-- Ground plane -->
    <include>
      <uri>https://fuel.gazebosim.org/1.0/OpenRobotics/models/Ground Plane</uri>
    </include>

    <!-- Sun (directional light) -->
    <include>
      <uri>https://fuel.gazebosim.org/1.0/OpenRobotics/models/Sun</uri>
    </include>

    <!-- Static obstacles -->
    <model name="lab_table">
      <static>true</static>
      <pose>2 0 0 0 0 0</pose>
      <link name="link">
        <collision name="collision">
          <geometry>
            <box>
              <size>1.5 0.8 0.75</size>
            </box>
          </geometry>
        </collision>
        <visual name="visual">
          <geometry>
            <box>
              <size>1.5 0.8 0.75</size>
            </box>
          </geometry>
          <material>
            <ambient>0.8 0.6 0.4 1</ambient>
            <diffuse>0.8 0.6 0.4 1</diffuse>
            <specular>0.1 0.1 0.1 1</specular>
          </material>
        </visual>
      </link>
    </model>

  </world>
</sdf>
```

**Launch World**:
```bash
gz sim indoor_lab.world
```

### Step 2: Lighting Configuration

**Lighting Types**:

```xml
<!-- 1. Directional Light (Sun) -->
<light type="directional" name="sun">
  <cast_shadows>true</cast_shadows>
  <pose>0 0 10 0 0 0</pose>
  <diffuse>0.8 0.8 0.8 1</diffuse>
  <specular>0.2 0.2 0.2 1</specular>
  <attenuation>
    <range>1000</range>
  </attenuation>
  <direction>-0.5 0.1 -0.9</direction>  <!-- Sun angle -->
</light>

<!-- 2. Point Light (Ceiling Lamp) -->
<light type="point" name="ceiling_light">
  <cast_shadows>false</cast_shadows>
  <pose>0 0 3 0 0 0</pose>
  <diffuse>1.0 1.0 0.9 1</diffuse>  <!-- Warm white -->
  <specular>0.5 0.5 0.5 1</specular>
  <attenuation>
    <range>20</range>
    <constant>0.5</constant>
    <linear>0.01</linear>
    <quadratic>0.001</quadratic>
  </attenuation>
</light>

<!-- 3. Spot Light (Task Light) -->
<light type="spot" name="task_light">
  <cast_shadows>true</cast_shadows>
  <pose>2 0 2 0 1.57 0</pose>  <!-- Point down at table -->
  <diffuse>1.0 1.0 1.0 1</diffuse>
  <specular>0.5 0.5 0.5 1</specular>
  <attenuation>
    <range>10</range>
    <linear>0.1</linear>
    <quadratic>0.01</quadratic>
  </attenuation>
  <spot>
    <inner_angle>0.6</inner_angle>  <!-- ~34Â° cone -->
    <outer_angle>1.0</outer_angle>  <!-- ~57Â° falloff -->
    <falloff>1.0</falloff>
  </spot>
  <direction>0 0 -1</direction>
</light>
```

**Lighting Presets** (time of day):

```python
#!/usr/bin/env python3
"""
Dynamic Lighting Controller
Changes lighting based on time of day
"""

import rclpy
from rclpy.node import Node
from std_msgs.msg import String
import subprocess

class LightingController(Node):
    def __init__(self):
        super().__init__('lighting_controller')

        # Lighting presets
        self.presets = {
            'dawn': {
                'sun_intensity': 0.3,
                'sun_color': (1.0, 0.8, 0.6),  # Orange
                'ambient': (0.2, 0.2, 0.3),
            },
            'noon': {
                'sun_intensity': 1.0,
                'sun_color': (1.0, 1.0, 1.0),  # White
                'ambient': (0.5, 0.5, 0.5),
            },
            'dusk': {
                'sun_intensity': 0.2,
                'sun_color': (1.0, 0.6, 0.4),  # Red-orange
                'ambient': (0.1, 0.1, 0.2),
            },
            'night': {
                'sun_intensity': 0.0,
                'sun_color': (0.1, 0.1, 0.2),  # Dark blue
                'ambient': (0.05, 0.05, 0.1),
            }
        }

        self.get_logger().info('Lighting controller initialized')

    def set_lighting(self, preset_name):
        """Apply lighting preset using Gazebo services"""
        if preset_name not in self.presets:
            self.get_logger().error(f'Unknown preset: {preset_name}')
            return

        preset = self.presets[preset_name]

        # Update sun light
        cmd = f"""
        gz service -s /world/indoor_lab/light_config \\
          --reqtype gz.msgs.Light \\
          --reptype gz.msgs.Boolean \\
          --req 'name: "sun", diffuse: {{r: {preset['sun_color'][0]}, g: {preset['sun_color'][1]}, b: {preset['sun_color'][2]}, a: {preset['sun_intensity']}}}'
        """
        subprocess.run(cmd, shell=True)

        self.get_logger().info(f'Applied lighting preset: {preset_name}')


def main(args=None):
    rclpy.init(args=args)
    node = LightingController()

    # Demo: cycle through presets
    presets = ['dawn', 'noon', 'dusk', 'night']
    import time
    for preset in presets:
        node.set_lighting(preset)
        time.sleep(5.0)

    node.destroy_node()
    rclpy.shutdown()


if __name__ == '__main__':
    main()
```

### Step 3: Object Spawning (Static and Dynamic)

**Static Objects** (in world file):

```xml
<!-- Warehouse shelving unit -->
<model name="shelf_unit">
  <static>true</static>
  <pose>5 0 0 0 0 1.57</pose>
  <link name="link">
    <!-- Frame -->
    <visual name="frame">
      <geometry>
        <box>
          <size>2.0 0.5 2.0</size>
        </box>
      </geometry>
      <material>
        <ambient>0.3 0.3 0.3 1</ambient>
        <diffuse>0.5 0.5 0.5 1</diffuse>
      </material>
    </visual>
    <collision name="collision">
      <geometry>
        <box>
          <size>2.0 0.5 2.0</size>
        </box>
      </geometry>
    </collision>
  </link>
</model>

<!-- Wall -->
<model name="wall_north">
  <static>true</static>
  <pose>0 10 1.5 0 0 0</pose>
  <link name="link">
    <collision name="collision">
      <geometry>
        <box>
          <size>20 0.2 3.0</size>
        </box>
      </geometry>
    </collision>
    <visual name="visual">
      <geometry>
        <box>
          <size>20 0.2 3.0</size>
        </box>
      </geometry>
      <material>
        <ambient>0.9 0.9 0.9 1</ambient>
        <diffuse>0.9 0.9 0.9 1</diffuse>
      </material>
    </visual>
  </link>
</model>
```

**Dynamic Object Spawning** (runtime):

```python
#!/usr/bin/env python3
"""
Dynamic Object Spawner
Spawn objects during simulation
"""

import rclpy
from rclpy.node import Node
import subprocess
import random

class ObjectSpawner(Node):
    def __init__(self):
        super().__init__('object_spawner')

        # Object library
        self.objects = {
            'box': """
                <sdf version="1.9">
                  <model name="box_{id}">
                    <pose>{x} {y} {z} 0 0 0</pose>
                    <link name="link">
                      <inertial>
                        <mass>0.5</mass>
                        <inertia>
                          <ixx>0.01</ixx>
                          <iyy>0.01</iyy>
                          <izz>0.01</izz>
                        </inertia>
                      </inertial>
                      <collision name="collision">
                        <geometry>
                          <box>
                            <size>0.2 0.2 0.2</size>
                          </box>
                        </geometry>
                      </collision>
                      <visual name="visual">
                        <geometry>
                          <box>
                            <size>0.2 0.2 0.2</size>
                          </box>
                        </geometry>
                        <material>
                          <ambient>{r} {g} {b} 1</ambient>
                          <diffuse>{r} {g} {b} 1</diffuse>
                        </material>
                      </visual>
                    </link>
                  </model>
                </sdf>
            """,
            'cylinder': """
                <sdf version="1.9">
                  <model name="cylinder_{id}">
                    <pose>{x} {y} {z} 0 0 0</pose>
                    <link name="link">
                      <inertial>
                        <mass>0.3</mass>
                        <inertia>
                          <ixx>0.005</ixx>
                          <iyy>0.005</iyy>
                          <izz>0.002</izz>
                        </inertia>
                      </inertial>
                      <collision name="collision">
                        <geometry>
                          <cylinder>
                            <radius>0.05</radius>
                            <length>0.15</length>
                          </cylinder>
                        </geometry>
                      </collision>
                      <visual name="visual">
                        <geometry>
                          <cylinder>
                            <radius>0.05</radius>
                            <length>0.15</length>
                          </cylinder>
                        </geometry>
                        <material>
                          <ambient>{r} {g} {b} 1</ambient>
                          <diffuse>{r} {g} {b} 1</diffuse>
                        </material>
                      </visual>
                    </link>
                  </model>
                </sdf>
            """
        }

        self.spawn_count = 0
        self.get_logger().info('Object spawner initialized')

    def spawn_object(self, obj_type, x, y, z):
        """Spawn object using gz service"""
        if obj_type not in self.objects:
            self.get_logger().error(f'Unknown object type: {obj_type}')
            return

        # Random color
        r, g, b = random.random(), random.random(), random.random()

        # Format SDF
        sdf_str = self.objects[obj_type].format(
            id=self.spawn_count,
            x=x, y=y, z=z,
            r=r, g=g, b=b
        )

        # Write to temp file
        sdf_file = f'/tmp/object_{self.spawn_count}.sdf'
        with open(sdf_file, 'w') as f:
            f.write(sdf_str)

        # Spawn via gz command
        cmd = f'gz service -s /world/indoor_lab/create --reqtype gz.msgs.EntityFactory --reptype gz.msgs.Boolean --req "sdf_filename: \\"{sdf_file}\\""'
        subprocess.run(cmd, shell=True)

        self.get_logger().info(f'Spawned {obj_type}_{self.spawn_count} at ({x:.2f}, {y:.2f}, {z:.2f})')
        self.spawn_count += 1

    def spawn_random_objects(self, count=10):
        """Spawn random objects in workspace"""
        for _ in range(count):
            obj_type = random.choice(['box', 'cylinder'])
            x = random.uniform(-3, 3)
            y = random.uniform(-3, 3)
            z = 1.0  # Above ground
            self.spawn_object(obj_type, x, y, z)


def main(args=None):
    rclpy.init(args=args)
    node = ObjectSpawner()

    # Spawn 20 random objects
    node.spawn_random_objects(count=20)

    node.destroy_node()
    rclpy.shutdown()


if __name__ == '__main__':
    main()
```

### Step 4: Environment Templates

**Kitchen Environment**:

```xml
<world name="kitchen">
  <physics name="default_physics" type="ode">
    <max_step_size>0.001</max_step_size>
    <real_time_factor>1.0</real_time_factor>
  </physics>

  <!-- Kitchen counter -->
  <model name="counter">
    <static>true</static>
    <pose>3 0 0.9 0 0 0</pose>
    <link name="link">
      <collision name="collision">
        <geometry>
          <box>
            <size>2.0 0.6 0.9</size>
          </box>
        </geometry>
      </collision>
      <visual name="visual">
        <geometry>
          <box>
            <size>2.0 0.6 0.9</size>
          </box>
        </geometry>
        <material>
          <ambient>0.7 0.7 0.7 1</ambient>
          <diffuse>0.8 0.8 0.8 1</diffuse>
        </material>
      </visual>
    </link>
  </model>

  <!-- Sink -->
  <model name="sink">
    <static>true</static>
    <pose>3 0 1.0 0 0 0</pose>
    <link name="link">
      <visual name="visual">
        <geometry>
          <box>
            <size>0.5 0.4 0.2</size>
          </box>
        </geometry>
        <material>
          <ambient>0.9 0.9 0.9 1</ambient>
          <diffuse>1.0 1.0 1.0 1</diffuse>
        </material>
      </visual>
    </link>
  </model>

  <!-- Cabinets -->
  <model name="cabinet_upper">
    <static>true</static>
    <pose>3 0 2.0 0 0 0</pose>
    <link name="link">
      <collision name="collision">
        <geometry>
          <box>
            <size>2.0 0.4 0.6</size>
          </box>
        </geometry>
      </collision>
      <visual name="visual">
        <geometry>
          <box>
            <size>2.0 0.4 0.6</size>
          </box>
        </geometry>
        <material>
          <ambient>0.6 0.4 0.2 1</ambient>
          <diffuse>0.7 0.5 0.3 1</diffuse>
        </material>
      </visual>
    </link>
  </model>

  <!-- Floor (tile pattern) -->
  <model name="floor">
    <static>true</static>
    <pose>0 0 0 0 0 0</pose>
    <link name="link">
      <collision name="collision">
        <geometry>
          <plane>
            <normal>0 0 1</normal>
            <size>10 10</size>
          </plane>
        </geometry>
      </collision>
      <visual name="visual">
        <geometry>
          <plane>
            <normal>0 0 1</normal>
            <size>10 10</size>
          </plane>
        </geometry>
        <material>
          <ambient>0.9 0.9 0.9 1</ambient>
          <diffuse>1.0 1.0 1.0 1</diffuse>
        </material>
      </visual>
    </link>
  </model>
</world>
```

**Warehouse Environment**:

```xml
<world name="warehouse">
  <physics name="default_physics" type="bullet">
    <max_step_size>0.002</max_step_size>
    <real_time_factor>1.0</real_time_factor>
  </physics>

  <!-- Large floor -->
  <model name="floor">
    <static>true</static>
    <link name="link">
      <collision name="collision">
        <geometry>
          <plane>
            <normal>0 0 1</normal>
            <size>50 50</size>
          </plane>
        </geometry>
      </collision>
      <visual name="visual">
        <geometry>
          <plane>
            <normal>0 0 1</normal>
            <size>50 50</size>
          </plane>
        </geometry>
        <material>
          <ambient>0.5 0.5 0.5 1</ambient>
          <diffuse>0.6 0.6 0.6 1</diffuse>
        </material>
      </visual>
    </link>
  </model>

  <!-- Warehouse lighting (high bay) -->
  <light type="point" name="bay_light_1">
    <pose>10 10 8 0 0 0</pose>
    <diffuse>1.0 1.0 0.9 1</diffuse>
    <attenuation>
      <range>30</range>
      <constant>0.1</constant>
      <linear>0.01</linear>
      <quadratic>0.001</quadratic>
    </attenuation>
  </light>

  <light type="point" name="bay_light_2">
    <pose>-10 10 8 0 0 0</pose>
    <diffuse>1.0 1.0 0.9 1</diffuse>
    <attenuation>
      <range>30</range>
      <constant>0.1</constant>
      <linear>0.01</linear>
      <quadratic>0.001</quadratic>
    </attenuation>
  </light>

  <!-- Pallet racks (repeated) -->
  <model name="pallet_rack_1">
    <static>true</static>
    <pose>15 0 0 0 0 0</pose>
    <link name="link">
      <collision name="collision">
        <geometry>
          <box>
            <size>1.2 3.0 4.0</size>
          </box>
        </geometry>
      </collision>
      <visual name="visual">
        <geometry>
          <box>
            <size>1.2 3.0 4.0</size>
          </box>
        </geometry>
        <material>
          <ambient>0.8 0.5 0.2 1</ambient>
          <diffuse>0.9 0.6 0.3 1</diffuse>
        </material>
      </visual>
    </link>
  </model>
</world>
```

### Step 5: World Plugins

**Wind Plugin** (environmental effects):

```xml
<plugin filename="gz-sim-wind-effects-system" name="gz::sim::systems::WindEffects">
  <horizontal>
    <magnitude>
      <time_for_rise>10</time_for_rise>
      <sin>
        <amplitude_percent>0.05</amplitude_percent>
        <period>60</period>
      </sin>
      <noise type="gaussian">
        <mean>0</mean>
        <stddev>0.0002</stddev>
      </noise>
    </magnitude>
    <direction>
      <time_for_rise>0</time_for_rise>
      <sin>
        <amplitude>5</amplitude>
        <period>20</period>
      </sin>
      <noise type="gaussian">
        <mean>0</mean>
        <stddev>0.03</stddev>
      </noise>
    </direction>
  </horizontal>
  <vertical>
    <noise type="gaussian">
      <mean>0</mean>
      <stddev>0.0002</stddev>
    </noise>
  </vertical>
</plugin>
```

**Scene Broadcaster** (for external visualization):

```xml
<plugin filename="gz-sim-scene-broadcaster-system" name="gz::sim::systems::SceneBroadcaster">
</plugin>
```

### Step 6: World Composition and Launch

**Multi-World Launch File**:

```python
import os
from ament_index_python.packages import get_package_share_directory
from launch import LaunchDescription
from launch.actions import DeclareLaunchArgument, ExecuteProcess
from launch.substitutions import LaunchConfiguration

def generate_launch_description():
    # World selection argument
    world_arg = DeclareLaunchArgument(
        'world',
        default_value='indoor_lab',
        description='World to load (indoor_lab, kitchen, warehouse)'
    )

    # Get world file path
    world_name = LaunchConfiguration('world')
    world_file = os.path.join(
        get_package_share_directory('humanoid_description'),
        'worlds',
        [world_name, '.world']
    )

    # Launch Gazebo
    gazebo = ExecuteProcess(
        cmd=['gz', 'sim', '-r', world_file],
        output='screen'
    )

    return LaunchDescription([
        world_arg,
        gazebo
    ])
```

**Usage**:
```bash
# Launch different worlds
ros2 launch humanoid_description world.launch.py world:=indoor_lab
ros2 launch humanoid_description world.launch.py world:=kitchen
ros2 launch humanoid_description world.launch.py world:=warehouse
```

## World Design Best Practices

**Performance Optimization**:
1. **Use static models** for non-moving objects (walls, floors, furniture)
2. **Simplify collision geometry** (use boxes/cylinders instead of meshes)
3. **Limit shadow-casting lights** (max 2-3 per scene)
4. **Disable physics** for decorative objects
5. **Use LOD (Level of Detail)** for distant objects

**Realism for Sim-to-Real**:
1. **Texture variation**: Don't use uniform colors, add noise
2. **Lighting diversity**: Mix directional, point, and spot lights
3. **Clutter**: Add background objects (not just task-relevant items)
4. **Imperfect geometry**: Slight rotations, non-aligned objects
5. **Scale accuracy**: Match real-world dimensions exactly

**Domain Randomization Parameters**:
```python
# Randomize during training
randomization_params = {
    'lighting': {
        'sun_intensity': (0.5, 1.5),
        'sun_direction': {'azimuth': (-45, 45), 'elevation': (30, 70)},
        'ambient_color': (0.3, 0.6),
    },
    'objects': {
        'pose_noise': 0.05,  # meters
        'rotation_noise': 0.1,  # radians
        'color_variation': 0.2,  # HSV jitter
    },
    'physics': {
        'friction': (0.4, 1.2),
        'mass_scale': (0.9, 1.1),
    }
}
```

---

## Agentic AI Integration

:::warning Agentic AI Consideration
**For autonomous robotics systems:**

Worlds are the "environment" that AI agents perceive, plan within, and act upon:

**World as Agent's Mental Model:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AI Agent's View                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  World State = {objects, poses, lighting, obstacles}    â”‚
â”‚                          â†“                               â”‚
â”‚  Perception â†’ Object Detection â†’ Scene Understanding    â”‚
â”‚                          â†“                               â”‚
â”‚  Planning â†’ Path Planning â†’ Manipulation Planning       â”‚
â”‚                          â†“                               â”‚
â”‚  Action â†’ Navigate â†’ Grasp â†’ Place                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Agentic Patterns:**

1. **Scene Understanding**: Extract semantic information from world
   ```python
   class WorldSceneGraph:
       """AI agent's internal representation of the world"""

       def get_objects_in_workspace(self) -> list[Object]:
           """Returns graspable objects within reach"""
           return self.query("objects WHERE distance_to_robot < 1.0m")

       def get_obstacles_on_path(self, goal: Pose) -> list[Obstacle]:
           """Returns obstacles between robot and goal"""
           return self.query(f"obstacles ON path_to({goal})")

       def get_surface_for_placement(self, object: Object) -> Surface:
           """Find suitable surface for object placement"""
           return self.query(f"surfaces WHERE supports({object.mass})")
   ```

2. **World Modification Planning**: Agent reasons about changing the world
   ```python
   def plan_world_modification(goal: str, current_world: World) -> list[Action]:
       """Agent plans how to modify world to achieve goal"""
       # Example: "Clear the table" requires identifying objects and planning removal
       objects_to_remove = current_world.objects_on("table")
       actions = []
       for obj in objects_to_remove:
           actions.append(Pick(obj))
           actions.append(Place(obj, "storage_bin"))
       return actions
   ```

3. **Domain Randomization for Robust Policies**: Expose agent to diverse worlds
4. **Counterfactual Reasoning**: "What if I move this obstacle?"

**LLM/Agent Interface Pattern:**
```python
class WorldInterface:
    """Interface for LLM agents to query and modify world state"""

    def describe_scene(self) -> str:
        """Natural language description for LLM reasoning"""
        return f"""
        Scene: Kitchen environment
        Objects: {len(self.objects)} items (3 cups, 2 plates, 1 knife)
        Obstacles: Table at center, cabinets on wall
        Lighting: Daytime, natural light from window
        Robot position: At counter, facing sink
        """

    def can_reach(self, object_name: str) -> bool:
        """Check if object is reachable without collision"""
        return self.planner.check_reachability(object_name)

    def spawn_object(self, object_type: str, pose: Pose) -> bool:
        """Allow agent to add objects for testing/training"""
        return self.world.spawn(object_type, pose)
```

**Safety Constraints for Autonomous Operation:**
- **Never** allow agents to spawn objects in collision with robot
- **Always** validate object poses are within workspace bounds
- **Require** human approval for world modifications in production
- **Log** all world state changes for debugging and replay
:::

:::tip Elite Insight: Procedural Worlds for Foundation Models
Large robotics foundation models (like Google's RT-2) use **procedural world generation** to create unlimited training scenarios:

1. **Parametric Templates**: Kitchen, warehouse, office base layouts
2. **Randomized Population**: Objects, lighting, clutter sampled from distributions
3. **Difficulty Curriculum**: Start simple, progressively add complexity
4. **Failure Injection**: Deliberately create edge cases (occluded objects, bad lighting)

The trend is toward "infinite worlds"â€”using generative models to create photorealistic, physically plausible environments at scale.
:::

---

## Practice Exercises

### Exercise 1: Foundation (Beginner)
**Objective:** Create a basic simulation world with lighting and objects

**Time:** ~20 minutes

**Skills Practiced:** SDF syntax, world structure, basic lighting

**Instructions:**
1. Create a new world file `my_first_world.world`:
   ```bash
   mkdir -p ~/ros2_ws/src/world_exercises/worlds
   cd ~/ros2_ws/src/world_exercises/worlds
   ```

2. Add the basic SDF structure with:
   - Physics configuration (ODE, 1ms timestep)
   - Ground plane
   - One directional light (sun)
   - One table (static model)

3. Launch and verify:
   ```bash
   gz sim my_first_world.world
   ```

**Success Criteria:**
- [ ] World loads without errors
- [ ] Ground plane visible
- [ ] Table casts shadow from sun
- [ ] Can orbit camera around scene

<details>
<summary>ðŸ’¡ Hint</summary>
Start with the minimal world template from Step 1. Add `<cast_shadows>true</cast_shadows>` to your directional light.
</details>

<details>
<summary>âœ… Solution</summary>

```xml
<?xml version="1.0"?>
<sdf version="1.9">
  <world name="my_first_world">
    <physics name="default" type="ode">
      <max_step_size>0.001</max_step_size>
      <real_time_factor>1.0</real_time_factor>
    </physics>

    <light type="directional" name="sun">
      <cast_shadows>true</cast_shadows>
      <pose>0 0 10 0 0 0</pose>
      <diffuse>0.8 0.8 0.8 1</diffuse>
      <direction>-0.5 0.1 -0.9</direction>
    </light>

    <model name="ground">
      <static>true</static>
      <link name="link">
        <collision name="collision">
          <geometry><plane><normal>0 0 1</normal></plane></geometry>
        </collision>
        <visual name="visual">
          <geometry><plane><normal>0 0 1</normal><size>20 20</size></plane></geometry>
        </visual>
      </link>
    </model>

    <model name="table">
      <static>true</static>
      <pose>2 0 0.375 0 0 0</pose>
      <link name="link">
        <collision name="collision">
          <geometry><box><size>1.0 0.6 0.75</size></box></geometry>
        </collision>
        <visual name="visual">
          <geometry><box><size>1.0 0.6 0.75</size></box></geometry>
        </visual>
      </link>
    </model>
  </world>
</sdf>
```
</details>

---

### Exercise 2: Dynamic Spawning (Intermediate)
**Objective:** Implement runtime object spawning with color variation

**Time:** ~30 minutes

**Skills Practiced:** Python scripting, Gazebo services, SDF generation

**Instructions:**
1. Modify the ObjectSpawner from Step 3 to:
   - Spawn objects in a grid pattern (3x3)
   - Assign colors based on position (red-yellow gradient)
   - Log each spawn with timestamp

2. Spawn 9 boxes on the table created in Exercise 1

3. Verify all objects have correct colors and positions

**Success Criteria:**
- [ ] 9 boxes spawn in 3x3 grid
- [ ] Colors vary from red (corner) to yellow (opposite corner)
- [ ] All boxes rest on table surface (not floating)
- [ ] Spawning completes in &lt;5 seconds

<details>
<summary>ðŸ’¡ Hint</summary>
Use linear interpolation for colors: `r = x/2, g = y/2, b = 0` for positions (x, y) in [0, 2].
</details>

---

### Exercise 3: Production Challenge (Advanced)
**Objective:** Create a domain-randomized kitchen environment for RL training

**Time:** ~60 minutes

**Skills Practiced:** Domain randomization, procedural generation, performance optimization

**Scenario:** You're training a robot to find and grasp cups in a kitchen. Create a world generation system that:
- Produces 100 unique kitchen configurations
- Randomizes lighting (3 presets: morning, noon, evening)
- Randomizes cup positions on counter (Â±10cm noise)
- Randomizes cup colors (3 variations)
- Maintains &gt;2x real-time simulation speed

**Requirements:**
1. Create a kitchen template world
2. Implement a Python script that generates variations
3. Validate each world loads correctly
4. Measure RTF for each configuration

**Constraints:**
- RTF must be â‰¥ 2.0 for all configurations
- No two configurations should be identical
- All cups must be reachable by robot arm

**Bonus Challenges:**
- [ ] Add distractor objects (plates, utensils)
- [ ] Implement weather effects (window glare)
- [ ] Generate training/validation/test splits

---

### Exercise 4: Architect's Design Challenge (Expert)
**Objective:** Design a procedural world generation pipeline for warehouse simulation

**Time:** ~2+ hours (can be ongoing)

**Scenario:** Design a system that generates unlimited unique warehouse configurations for training 50 mobile robots simultaneously. The system must support:
- Variable warehouse sizes (small: 20x20m, large: 100x100m)
- Dynamic shelf layouts (grid, aisle, random)
- Package diversity (1000+ unique SKUs with varying sizes/weights)
- Realistic lighting (high-bay LEDs, emergency lights, loading dock daylight)

**Design Requirements:**
1. Define the procedural generation grammar (layout rules)
2. Design the object database schema (packages, shelves, obstacles)
3. Plan for texture/material variation pipeline
4. Define validation criteria for generated worlds

**Deliverables:**
- Architecture diagram for generation pipeline
- Grammar specification for layout generation
- Performance analysis (worlds/minute, memory usage)
- Sample generated worlds with screenshots

**Considerations:**
- GPU memory limits for 50 simultaneous robots
- Reproducibility (seed-based generation for debugging)
- Integration with RL training loop (reset time)

---

## Enhanced Troubleshooting Guide

### Quick Fixes

| Symptom | Likely Cause | Quick Fix |
|---------|--------------|-----------|
| Black screen | No lights | Add directional light with `<diffuse>0.8 0.8 0.8 1</diffuse>` |
| World won't load | SDF syntax error | Run `gz sdf --check world.world` |
| Objects fall through floor | Missing collision | Add `<collision>` to ground plane |
| Slow rendering | Too many shadows | Set `<cast_shadows>false</cast_shadows>` on point lights |
| Spawn fails | World name mismatch | Verify world name in spawn service URL |

### Diagnostic Decision Tree

```
World not loading?
â”œâ”€â”€ Check SDF syntax: gz sdf --check world.world
â”‚   â”œâ”€â”€ Syntax error â†’ Fix XML (check closing tags)
â”‚   â””â”€â”€ No errors â†’ Check file path
â””â”€â”€ File path correct?
    â”œâ”€â”€ Yes â†’ Check Gazebo version compatibility
    â””â”€â”€ No â†’ Use absolute path or verify working directory

Objects not visible?
â”œâ”€â”€ Check if spawned: gz model --list
â”‚   â”œâ”€â”€ Not listed â†’ Spawn command failed
â”‚   â””â”€â”€ Listed â†’ Check pose (might be underground or out of view)
â”œâ”€â”€ Check lighting: Are there any lights in world?
â””â”€â”€ Check materials: Ensure ambient/diffuse not (0,0,0,0)
```

### Deep Dive: Lighting Issues

**Symptoms:**
- Scene too dark or too bright
- No shadows visible
- Unrealistic "flat" lighting

**Root Causes:**
1. **Missing directional light** - Probability: High
2. **Ambient too high** - Probability: Medium
3. **Shadow disabled** - Probability: Medium
4. **Material misconfiguration** - Probability: Low

**Diagnosis Steps:**
```bash
# Step 1: List all lights in world
gz light --list
# Expected: At least one directional light

# Step 2: Check light properties
gz light -m <light_name> -p
# Verify: diffuse, direction, cast_shadows

# Step 3: Check scene ambient
gz scene -p
# Look for: ambient values (should be ~0.3-0.5)
```

**Solutions:**
- **If Cause 1:** Add directional light (sun) to world
- **If Cause 2:** Reduce `<ambient>` to 0.3 0.3 0.3 1
- **If Cause 3:** Add `<cast_shadows>true</cast_shadows>` to lights
- **If Cause 4:** Check material `<ambient>` and `<diffuse>` values

**Prevention:**
- Always start with the standard lighting template
- Test world at multiple times of day (dawn, noon, dusk)
- Compare rendered images to real photographs

---

## Summary

### Key Commands Reference

```bash
# Launch world
gz sim <world_file.world>

# Check SDF syntax
gz sdf --check <world_file.world>

# List models in world
gz model --list

# Spawn model from file
gz service -s /world/<world_name>/create \
  --reqtype gz.msgs.EntityFactory \
  --reptype gz.msgs.Boolean \
  --req 'sdf_filename: "/path/to/model.sdf"'

# Delete model
gz service -s /world/<world_name>/remove \
  --reqtype gz.msgs.Entity \
  --reptype gz.msgs.Boolean \
  --req 'name: "model_name"'

# List lights
gz light --list
```

### World Design Checklist

Before deploying a world configuration:
- [ ] SDF validates without errors
- [ ] At least one directional light with shadows
- [ ] Ground plane has collision geometry
- [ ] All static models marked `<static>true</static>`
- [ ] Performance tested (RTF meets requirements)
- [ ] Lighting calibrated against real environment
- [ ] Domain randomization ranges validated
- [ ] Object spawning tested for edge cases

### Configuration Templates

**Minimal World (Quick Start):**
```xml
<world name="minimal">
  <physics type="ode"><max_step_size>0.001</max_step_size></physics>
  <light type="directional" name="sun"><cast_shadows>true</cast_shadows></light>
  <include><uri>https://fuel.gazebosim.org/1.0/OpenRobotics/models/Ground Plane</uri></include>
</world>
```

**Production World (Full Features):**
- Physics: Bullet with GPU acceleration
- Lights: 1 directional + 3 point lights
- Ground: Textured with friction
- Objects: Dynamic spawning enabled
- Plugins: Wind, scene broadcaster

## Next Steps

With world design mastered, proceed to:
- **M2-C1-S4**: Sensor Plugins (camera, lidar, IMU simulation)
- **M2-C1-S5**: Contact Dynamics (friction, grasp physics)
- **M2-C1-S6**: Model Assets (meshes, textures, materials)

**Troubleshooting**:
- **World won't load**: Check SDF syntax with `gz sdf --check world.world`
- **Black screen**: Verify lighting (at least one light source required)
- **Slow rendering**: Disable shadows, reduce light count, simplify geometry
- **Objects fall through floor**: Ensure ground plane has collision geometry
- **Lighting too dark/bright**: Adjust ambient + diffuse values, check shadow settings

**Real-World World Design**:
- **NASA JPL**: Mars terrain worlds for rover testing (procedural generation)
- **Amazon Robotics**: Warehouse worlds with 1000+ objects for pick-and-place
- **Waymo**: Urban environments with traffic, pedestrians, weather conditions

**World Asset Resources**:
- **Fuel**: https://fuel.gazebosim.org (official model repository)
- **Gazebo Models**: https://github.com/osrf/gazebo_models
- **AWS RoboMaker**: WorldForge procedural world generation

---

**Assessment Preparation**: This section prepares for **Assessment 3: Simulation and Sim-to-Real (Week 9)**. You must demonstrate creating custom worlds, dynamic object spawning, and lighting configuration.
